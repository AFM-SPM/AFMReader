{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to AFMReader AFMReader is a Python package for loading Atomic Force Microscopy (AFM) image files and metadata. It is primarily used by the TopoStats package for loading AFM images for processing. Both AFMReader and packages are written and maintained by members of the Pyne Lab based at the University of Sheffield . Introduction Installation Usage Contributing Workflow Links API Citing If you use or depend on AFMReader in your software please consider citing it in any derivative work that is published. Citation details can be found in the CITATION.cff file in the source repository. Please email us at topostats@sheffield.ac.uk with details of your package us if you use AFMReader in your software.","title":"Home"},{"location":"#welcome-to-afmreader","text":"AFMReader is a Python package for loading Atomic Force Microscopy (AFM) image files and metadata. It is primarily used by the TopoStats package for loading AFM images for processing. Both AFMReader and packages are written and maintained by members of the Pyne Lab based at the University of Sheffield . Introduction Installation Usage Contributing Workflow Links API","title":"Welcome to AFMReader"},{"location":"#citing","text":"If you use or depend on AFMReader in your software please consider citing it in any derivative work that is published. Citation details can be found in the CITATION.cff file in the source repository. Please email us at topostats@sheffield.ac.uk with details of your package us if you use AFMReader in your software.","title":"Citing"},{"location":"api/","text":"API asd.py gwy.py ibw.py io jpk.py logging spm.py topostats.py","title":"API"},{"location":"api/#api","text":"asd.py gwy.py ibw.py io jpk.py logging spm.py topostats.py","title":"API"},{"location":"contributing/","text":"Contributing This document describes how to contribute to the development of this software. Bug Reports If you find a but we need to know about it so we can fix it. Please report your bugs on our GitHub Issues page . Feature Requests If you find AFMReader useful but think it can be improved you can make a feature request . Code Contributions If you would like to fix a bug or add a new feature that is great, Pull Requests are very welcome. However, we have adopted a number of good software development practises that ensure the code and documentation is linted and that unit and regression tests pass both locally and on Continuous Integration. The rest of this page helps explain how to set yourself up with these various tools. Virtual Environments Use of virtual environments , particularly during development of Python packages, is encouraged. There are lots of options out there for you to choose from including... Miniconda venv virtualenvwrapper Which you choose is up to you, although you should be wary of using the Miniconda distribution from Anaconda if any of your work is carried out for or in conjunction with a commercial entity. uv Developers are using the uv package manager to setup and control environments to which end a uv.lock file is included in the repository. uv supports managing virtual environments so you may wish to install and use this tool at the system level to manage your virtual environments for this package. Cloning the Repository Once you have setup your virtual environment you should clone the repository from GitHub cd ~/path/you/want/to/clone/to git clone https://github.com/AFM-SPM/AFMReader Install development Once you have cloned the AFMReader repository you should install all the package along with all development and documentation dependencies in \"editable\" mode. This means you can test the changes you make in real time. cd AFMReader pip install --no-cache-dir -e . [ docs,dev,tests ] Git Git is used to version control development of the package. The main branch on GitHub and the pre-commit hooks have protections in place that prevent committing/pushing directly to the main branch. This means you should create a branch to undertake development or fix bugs. Issues Ideally an issue should have been created detailing the feature request. If it is a large amount of work this should be captured in an issue labelled \" Epic \" and the steps taken to achieve all work broken down into smaller issues. Branch nomenclature When undertaking work on a particular issue it is useful to use informative branch names. These convey information about what the branch is for beyond simply \" adding-feature-x \". We ask that you create the branch using your GitHub username, followed by the issue number and a short description of the work being undertaken. For example ns-rse/1021-add-xyz-support as this allows others to know who has been undertaking the work, what issue the work relates to and has an informative name as to the nature of that work. Conventional Commits We also ask that you try and follow the Conventional Commits pattern for titling your commits and where required include additional information on why you have made the changes you are committing. Linting Linting is the practice of following a consistent coding style. For Python that style is defined in PEP8 . By following a consistent style across a code base it is easier to read and understand the code written by others (including your past self!). We use the following linters implemented as pre-commit hooks Python Black Blacken-docs flake8 Numpydoc Ruff Other Codespell (Spelling across all filesyy) markdownlint-cli2 (Markdown) prettier (Markdown, YAML) Pre-commit Style checks are made using the pre-commit framework which is one of the development dependencies and should have been installed in the previous step. You can check if its is installed in your virtual environment with pip show pre-commit . If you have pre-commit installed install the hook using... pre-commit install This adds a file to .git/hooks/pre-commit that will run all of the hooks specified in .pre-commit-config.yaml . The first time these are run it will take a little while as a number of virtual environments are downloaded for the first time. It might be a good time to run these manually on the code base you have just cloned which should pass all checks. pre-commit run --all-files These should all pass. Now whenever you try to make a git commit these checks will run before the commit is made and if any fail you will be advised of what has failed. Some of the linters such as Black and Ruff will automatically correct any errors that they find and you will have to stage the files that have changed again. Not all errors can be automatically corrected (e.g. Numpydoc validation and Pylint ) and you will have to manually correct these. Docstrings It is sensible and easiest to write informative docstrings when first defining your modules, classes and methods/functions. Doing so is a useful adie-memoire not only for others but your future self and with modern Language Servers that will, on configuration, show you the docstrings when using the functions it helps save time. You will find your commits fail the numpydoc-validation pre-commit hook if you do not write docstrings and will be prompted to add one. Testing We use the pytest framework with various plugins in our testing suite. When correcting bugs and adding features at a bare minimum the existing tests should not fail. Where possible we would be grateful of contributions to the test suite. This means if an edge case has been identified and a solution derived a test is added that checks the edge case is correctly handled. For new features would ideally mean writing unit-tests to ensure each function or method works as intended and for larger classes that behaviour is as expected. Sometimes tests will need updating in light of bug fixes and features which is to be expected, but remember to commit updates to tests as well as to code to ensure the Continuous Integration tests pass. Pytest-testmon To shorten the feedback loop during development the pytest-testmon plugin is used as a pre-commit hook so that only the tests affected by the changes that are being committed are run. This requires that on first installing the package you create a local database of the state of the tests by running the following... pytest --test-mon This creates the files .testmondata which stores the current state of tests. Once created commits will only run affected tests. However if your environment has changed, such as adding new packages or updating installed packages you will have to recreate the database. Pull Requests Once you have made your changes and committed them you will at some point wish to make a Pull Request to merge them into the main branch. In order to keep Git history clean and easier to understand you can perform an interactive git rebase -i on your feature branch to squash related commits and tidy up your commit history. When your branch is ready for merging with main open a Pull Request . You can use the GitHub keywords of close[s|d] / fix[es|ed] / resolve[s|d] followed by the issue number in the body of your commit message which will change the status of the issue to \" Closed \" when the Pull Request is merged. Pull Requests will be reviewed in a timely and hopefully constructive manner.","title":"Contributing"},{"location":"contributing/#contributing","text":"This document describes how to contribute to the development of this software.","title":"Contributing"},{"location":"contributing/#bug-reports","text":"If you find a but we need to know about it so we can fix it. Please report your bugs on our GitHub Issues page .","title":"Bug Reports"},{"location":"contributing/#feature-requests","text":"If you find AFMReader useful but think it can be improved you can make a feature request .","title":"Feature Requests"},{"location":"contributing/#code-contributions","text":"If you would like to fix a bug or add a new feature that is great, Pull Requests are very welcome. However, we have adopted a number of good software development practises that ensure the code and documentation is linted and that unit and regression tests pass both locally and on Continuous Integration. The rest of this page helps explain how to set yourself up with these various tools.","title":"Code Contributions"},{"location":"contributing/#virtual-environments","text":"Use of virtual environments , particularly during development of Python packages, is encouraged. There are lots of options out there for you to choose from including... Miniconda venv virtualenvwrapper Which you choose is up to you, although you should be wary of using the Miniconda distribution from Anaconda if any of your work is carried out for or in conjunction with a commercial entity.","title":"Virtual Environments"},{"location":"contributing/#uv","text":"Developers are using the uv package manager to setup and control environments to which end a uv.lock file is included in the repository. uv supports managing virtual environments so you may wish to install and use this tool at the system level to manage your virtual environments for this package.","title":"uv"},{"location":"contributing/#cloning-the-repository","text":"Once you have setup your virtual environment you should clone the repository from GitHub cd ~/path/you/want/to/clone/to git clone https://github.com/AFM-SPM/AFMReader","title":"Cloning the Repository"},{"location":"contributing/#install-development","text":"Once you have cloned the AFMReader repository you should install all the package along with all development and documentation dependencies in \"editable\" mode. This means you can test the changes you make in real time. cd AFMReader pip install --no-cache-dir -e . [ docs,dev,tests ]","title":"Install development"},{"location":"contributing/#git","text":"Git is used to version control development of the package. The main branch on GitHub and the pre-commit hooks have protections in place that prevent committing/pushing directly to the main branch. This means you should create a branch to undertake development or fix bugs.","title":"Git"},{"location":"contributing/#issues","text":"Ideally an issue should have been created detailing the feature request. If it is a large amount of work this should be captured in an issue labelled \" Epic \" and the steps taken to achieve all work broken down into smaller issues.","title":"Issues"},{"location":"contributing/#branch-nomenclature","text":"When undertaking work on a particular issue it is useful to use informative branch names. These convey information about what the branch is for beyond simply \" adding-feature-x \". We ask that you create the branch using your GitHub username, followed by the issue number and a short description of the work being undertaken. For example ns-rse/1021-add-xyz-support as this allows others to know who has been undertaking the work, what issue the work relates to and has an informative name as to the nature of that work.","title":"Branch nomenclature"},{"location":"contributing/#conventional-commits","text":"We also ask that you try and follow the Conventional Commits pattern for titling your commits and where required include additional information on why you have made the changes you are committing.","title":"Conventional Commits"},{"location":"contributing/#linting","text":"Linting is the practice of following a consistent coding style. For Python that style is defined in PEP8 . By following a consistent style across a code base it is easier to read and understand the code written by others (including your past self!). We use the following linters implemented as pre-commit hooks Python Black Blacken-docs flake8 Numpydoc Ruff Other Codespell (Spelling across all filesyy) markdownlint-cli2 (Markdown) prettier (Markdown, YAML)","title":"Linting"},{"location":"contributing/#pre-commit","text":"Style checks are made using the pre-commit framework which is one of the development dependencies and should have been installed in the previous step. You can check if its is installed in your virtual environment with pip show pre-commit . If you have pre-commit installed install the hook using... pre-commit install This adds a file to .git/hooks/pre-commit that will run all of the hooks specified in .pre-commit-config.yaml . The first time these are run it will take a little while as a number of virtual environments are downloaded for the first time. It might be a good time to run these manually on the code base you have just cloned which should pass all checks. pre-commit run --all-files These should all pass. Now whenever you try to make a git commit these checks will run before the commit is made and if any fail you will be advised of what has failed. Some of the linters such as Black and Ruff will automatically correct any errors that they find and you will have to stage the files that have changed again. Not all errors can be automatically corrected (e.g. Numpydoc validation and Pylint ) and you will have to manually correct these.","title":"Pre-commit"},{"location":"contributing/#docstrings","text":"It is sensible and easiest to write informative docstrings when first defining your modules, classes and methods/functions. Doing so is a useful adie-memoire not only for others but your future self and with modern Language Servers that will, on configuration, show you the docstrings when using the functions it helps save time. You will find your commits fail the numpydoc-validation pre-commit hook if you do not write docstrings and will be prompted to add one.","title":"Docstrings"},{"location":"contributing/#testing","text":"We use the pytest framework with various plugins in our testing suite. When correcting bugs and adding features at a bare minimum the existing tests should not fail. Where possible we would be grateful of contributions to the test suite. This means if an edge case has been identified and a solution derived a test is added that checks the edge case is correctly handled. For new features would ideally mean writing unit-tests to ensure each function or method works as intended and for larger classes that behaviour is as expected. Sometimes tests will need updating in light of bug fixes and features which is to be expected, but remember to commit updates to tests as well as to code to ensure the Continuous Integration tests pass.","title":"Testing"},{"location":"contributing/#pytest-testmon","text":"To shorten the feedback loop during development the pytest-testmon plugin is used as a pre-commit hook so that only the tests affected by the changes that are being committed are run. This requires that on first installing the package you create a local database of the state of the tests by running the following... pytest --test-mon This creates the files .testmondata which stores the current state of tests. Once created commits will only run affected tests. However if your environment has changed, such as adding new packages or updating installed packages you will have to recreate the database.","title":"Pytest-testmon"},{"location":"contributing/#pull-requests","text":"Once you have made your changes and committed them you will at some point wish to make a Pull Request to merge them into the main branch. In order to keep Git history clean and easier to understand you can perform an interactive git rebase -i on your feature branch to squash related commits and tidy up your commit history. When your branch is ready for merging with main open a Pull Request . You can use the GitHub keywords of close[s|d] / fix[es|ed] / resolve[s|d] followed by the issue number in the body of your commit message which will change the status of the issue to \" Closed \" when the Pull Request is merged. Pull Requests will be reviewed in a timely and hopefully constructive manner.","title":"Pull Requests"},{"location":"installation/","text":"Installation PyPI Versioned releases of AFMReader are available on the Python Package Index (PyPI) and can be installed, ideally in a virtual environment, using the following pip command. pip install AFMReader Development Alternatively you can install the latest development release can be installed directly from GitHub using pip pip install git+https://github.com/AFM-SPM/AFMReader.git As per the documentation you can install specific commits, branches or tagged releases in this manner by appending @<commit> , @<branch> or @<tag> . Please refer to the pip documentation for further details.","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#pypi","text":"Versioned releases of AFMReader are available on the Python Package Index (PyPI) and can be installed, ideally in a virtual environment, using the following pip command. pip install AFMReader","title":"PyPI"},{"location":"installation/#development","text":"Alternatively you can install the latest development release can be installed directly from GitHub using pip pip install git+https://github.com/AFM-SPM/AFMReader.git As per the documentation you can install specific commits, branches or tagged releases in this manner by appending @<commit> , @<branch> or @<tag> . Please refer to the pip documentation for further details.","title":"Development"},{"location":"introduction/","text":"Introduction AFMReader is a Python package for loading Atomic Force Microscopy (AFM) image files. It is primarily used by the TopoStats package for loading AFM images for processing. Both AFMReader and packages are written and maintained by members of the Pyne Lab based at the University of Sheffield . Citing If you use or depend on AFMReader in your software please consider citing it in any derivative work that is published. Citation details can be found in the CITATION.cff file in the source repository. Please email us at topostats@sheffield.ac.uk with details of your package if you use AFMReader in your software.","title":"Introduction"},{"location":"introduction/#introduction","text":"AFMReader is a Python package for loading Atomic Force Microscopy (AFM) image files. It is primarily used by the TopoStats package for loading AFM images for processing. Both AFMReader and packages are written and maintained by members of the Pyne Lab based at the University of Sheffield .","title":"Introduction"},{"location":"introduction/#citing","text":"If you use or depend on AFMReader in your software please consider citing it in any derivative work that is published. Citation details can be found in the CITATION.cff file in the source repository. Please email us at topostats@sheffield.ac.uk with details of your package if you use AFMReader in your software.","title":"Citing"},{"location":"links/","text":"Links Links to related software. AFM-SPM AFM-SPM GitHub Organisation TopoStats AFMReader Related Software TopoStats is one of many pieces of software available for working with Atomic Force Microscopy data, other packages, many of which we leverage in AFMReader and TopoStats are detailed here. Python afmformats reading common AFM file formats. gwyfile a pure Python interface to reading and writing Gwyddion files. magni compressive sampling and reconstruction of Atomic Force Microscopy images. nanite loading, fitting and rating AFM force-distance data. nanoforce import and analyse AFM force curves produced using Nanoscope 5 & 6 and Nanosurf .nid files. nanoscope read data files collected using Bruker, Veeco, and Digital Instruments Atomic Force Microscopes (AFMs) using Nanoscope v5.12 - v10.00 acquisition software NSFOpen Read data and parameters from Nanosurf NID files. pycroscopy Python Package for scientific analysis of nanoscience data. pySPM read, handle and plot Scanning Probme Microscopy (SPM) images and ToF-SIMS data. C++ libasd library for reading asd files, includes Python 3 bindings. Other gwyddion a modular program for Scanning Probe Microscopy (SPM) data visualisation and analysis.","title":"Links"},{"location":"links/#links","text":"Links to related software.","title":"Links"},{"location":"links/#afm-spm","text":"AFM-SPM GitHub Organisation TopoStats AFMReader","title":"AFM-SPM"},{"location":"links/#related-software","text":"TopoStats is one of many pieces of software available for working with Atomic Force Microscopy data, other packages, many of which we leverage in AFMReader and TopoStats are detailed here.","title":"Related Software"},{"location":"links/#python","text":"afmformats reading common AFM file formats. gwyfile a pure Python interface to reading and writing Gwyddion files. magni compressive sampling and reconstruction of Atomic Force Microscopy images. nanite loading, fitting and rating AFM force-distance data. nanoforce import and analyse AFM force curves produced using Nanoscope 5 & 6 and Nanosurf .nid files. nanoscope read data files collected using Bruker, Veeco, and Digital Instruments Atomic Force Microscopes (AFMs) using Nanoscope v5.12 - v10.00 acquisition software NSFOpen Read data and parameters from Nanosurf NID files. pycroscopy Python Package for scientific analysis of nanoscience data. pySPM read, handle and plot Scanning Probme Microscopy (SPM) images and ToF-SIMS data.","title":"Python"},{"location":"links/#c","text":"libasd library for reading asd files, includes Python 3 bindings.","title":"C++"},{"location":"links/#other","text":"gwyddion a modular program for Scanning Probe Microscopy (SPM) data visualisation and analysis.","title":"Other"},{"location":"usage/","text":"Usage AFMReader currently obtains the raw image data from your selected channel, and the pixel-to-nanometre scaling value (pixels are assumed to be square) for the physical dimensions of the image for all formats except the .topostats format. The .topostats metadata will contain that from the processing steps from TopoStats . If you wish to process AFM images supported by AFMReader it is recommend you use TopoStats to do so, however the library can be used on its own if you wish to integrate it into your workflow. Supported file formats File format Description .asd High-speed AFM .ibw WaveMetrics .spm Bruker's Format .jpk Bruker .topostats TopoStats .gwy Gwydion Support for the following additional formats is planned. Some of these are already supported in TopoStats and are awaiting refactoring to move their functionality into AFMReader these are denoted in bold below. File format Description Status .nhf Nanosurf To Be Implemented. .aris Imaris Oxford Instruments To Be Implemented. .tiff Park Systems To Be Implemented. Configuration A default configuration is included in the package which contains options for loading different file formats. This is a YAML file with keys for each file type and the relevant key/value pair nested within. The table below details the current configuration options. If loading a file format supports a custom configuration file then it can be specified with the config_path parameter which should point to the location of the file. File format Keys Default value jpk n_slots 32896 default_slot 32897 first_slot_tag 32912 first_scaling_type 32931 first_scaling_name 32932 first_offset_name 32933 channel_name 32848 trace_retrace 32849 grid_ulength 32834 grid_vlength 32835 grid_ilength 32838 grid_jlength 32839 slot_size 48 .topostats You can open .topostats files using the load_topostats function. Just pass in the path to the file. from AFMReader.topostats import load_topostats image , pixel_to_nanometre_scaling_factor , metadata = load_topostats ( file_path = \"./my_topostats_file.topostats\" ) .spm You can open .spm files using the load_spm function. Just pass in the path to the file and the channel name that you want to use. (If in doubt use one of the following: \"Height\", \"ZSensor\", \"Height Sensor\"). from AFMReader.spm import load_spm image , pixel_to_nanometre_scaling_factor = load_spm ( file_path = \"./my_spm_file.spm\" , channel = \"Height\" ) .gwy You can open .gwy files using the load_gwy function. Just pass in the path to the file and the channel name that you want to use. (If in doubt use one one of the following: \"Height\", \"ZSensor\", \"Height Sensor\"). from AFMReader.gwy import load_gwy image , pixel_to_nanometre_scaling_factor = load_gwy ( file_path = \"./my_gwy_file.gwy\" , channel = \"Height\" ) .asd You can open .asd files using the load_asd function. Just pass in the path to the file and the channel name that you want to use. (If in doubt use the \"TP\" topography channel). Note: For .asd files, there seem to only ever be two channels in one file. \"TP\" (topography) is the main one you will want to use unless you know you specifically want something else. Other channels: \"ER\" - Error, \"PH\" - Phase from AFMReader.asd import load_asd frames , pixel_to_nanometre_scaling_factor , metadata = load_asd ( file_path = \"./my_asd_file.asd\" , channel = \"TP\" ) .ibw You can open .ibw files using the load_ibw function. Just pass in the path to the file and the channel name that you want to use. (If in doubt, use HeightTracee (yes, with the extra 'e'), ZSensorTrace , or ZSensor ). from AFMReader.ibw import load_ibw image , pixel_to_nanometre_scaling_factor = load_ibw ( file_path = \"./my_ibw_file.ibw\" , channel = \"HeightTrace\" ) .jpk You can open .jpk files using the load_jpk function. Just pass in the path to the file and the channel name you want to use. (If in doubt, use height_trace or measuredHeight_trace ). from AFMReader.jpk import load_jpk image , pixel_to_nanometre_scaling_factor = load_jpk ( file_path = \"./my_jpk_file.jpk\" , channel = \"height_trace\" )","title":"Usage"},{"location":"usage/#usage","text":"AFMReader currently obtains the raw image data from your selected channel, and the pixel-to-nanometre scaling value (pixels are assumed to be square) for the physical dimensions of the image for all formats except the .topostats format. The .topostats metadata will contain that from the processing steps from TopoStats . If you wish to process AFM images supported by AFMReader it is recommend you use TopoStats to do so, however the library can be used on its own if you wish to integrate it into your workflow.","title":"Usage"},{"location":"usage/#supported-file-formats","text":"File format Description .asd High-speed AFM .ibw WaveMetrics .spm Bruker's Format .jpk Bruker .topostats TopoStats .gwy Gwydion Support for the following additional formats is planned. Some of these are already supported in TopoStats and are awaiting refactoring to move their functionality into AFMReader these are denoted in bold below. File format Description Status .nhf Nanosurf To Be Implemented. .aris Imaris Oxford Instruments To Be Implemented. .tiff Park Systems To Be Implemented.","title":"Supported file formats"},{"location":"usage/#configuration","text":"A default configuration is included in the package which contains options for loading different file formats. This is a YAML file with keys for each file type and the relevant key/value pair nested within. The table below details the current configuration options. If loading a file format supports a custom configuration file then it can be specified with the config_path parameter which should point to the location of the file. File format Keys Default value jpk n_slots 32896 default_slot 32897 first_slot_tag 32912 first_scaling_type 32931 first_scaling_name 32932 first_offset_name 32933 channel_name 32848 trace_retrace 32849 grid_ulength 32834 grid_vlength 32835 grid_ilength 32838 grid_jlength 32839 slot_size 48","title":"Configuration"},{"location":"usage/#topostats","text":"You can open .topostats files using the load_topostats function. Just pass in the path to the file. from AFMReader.topostats import load_topostats image , pixel_to_nanometre_scaling_factor , metadata = load_topostats ( file_path = \"./my_topostats_file.topostats\" )","title":".topostats"},{"location":"usage/#spm","text":"You can open .spm files using the load_spm function. Just pass in the path to the file and the channel name that you want to use. (If in doubt use one of the following: \"Height\", \"ZSensor\", \"Height Sensor\"). from AFMReader.spm import load_spm image , pixel_to_nanometre_scaling_factor = load_spm ( file_path = \"./my_spm_file.spm\" , channel = \"Height\" )","title":".spm"},{"location":"usage/#gwy","text":"You can open .gwy files using the load_gwy function. Just pass in the path to the file and the channel name that you want to use. (If in doubt use one one of the following: \"Height\", \"ZSensor\", \"Height Sensor\"). from AFMReader.gwy import load_gwy image , pixel_to_nanometre_scaling_factor = load_gwy ( file_path = \"./my_gwy_file.gwy\" , channel = \"Height\" )","title":".gwy"},{"location":"usage/#asd","text":"You can open .asd files using the load_asd function. Just pass in the path to the file and the channel name that you want to use. (If in doubt use the \"TP\" topography channel). Note: For .asd files, there seem to only ever be two channels in one file. \"TP\" (topography) is the main one you will want to use unless you know you specifically want something else. Other channels: \"ER\" - Error, \"PH\" - Phase from AFMReader.asd import load_asd frames , pixel_to_nanometre_scaling_factor , metadata = load_asd ( file_path = \"./my_asd_file.asd\" , channel = \"TP\" )","title":".asd"},{"location":"usage/#ibw","text":"You can open .ibw files using the load_ibw function. Just pass in the path to the file and the channel name that you want to use. (If in doubt, use HeightTracee (yes, with the extra 'e'), ZSensorTrace , or ZSensor ). from AFMReader.ibw import load_ibw image , pixel_to_nanometre_scaling_factor = load_ibw ( file_path = \"./my_ibw_file.ibw\" , channel = \"HeightTrace\" )","title":".ibw"},{"location":"usage/#jpk","text":"You can open .jpk files using the load_jpk function. Just pass in the path to the file and the channel name you want to use. (If in doubt, use height_trace or measuredHeight_trace ). from AFMReader.jpk import load_jpk image , pixel_to_nanometre_scaling_factor = load_jpk ( file_path = \"./my_jpk_file.jpk\" , channel = \"height_trace\" )","title":".jpk"},{"location":"workflow/","text":"Workflow flowchart TB %% Styles classDef input fill:#b3d9ff,stroke:#333,stroke-width:2px classDef core fill:#90EE90,stroke:#333,stroke-width:2px classDef output fill:#FFB366,stroke:#333,stroke-width:2px classDef test fill:#E6E6FA,stroke:#333,stroke-width:2px classDef tools fill:#FFE4B5,stroke:#333,stroke-width:2px %% Input Layer subgraph InputFormats ASD[\".asd Files\"]:::input IBW[\".ibw Files\"]:::input SPM[\".spm Files\"]:::input JPK[\".jpk Files\"]:::input TOPO[\".topostats Files\"]:::input GWY[\".gwy Files\"]:::input end %% Core Processing Layer subgraph CoreProcessing IO[\"IO Module\\n(Base Reader)\"]:::core LOG[\"Logging Module\"]:::core subgraph FormatHandlers ASDHandler[\"ASD Handler\"]:::core IBWHandler[\"IBW Handler\"]:::core SPMHandler[\"SPM Handler\"]:::core JPKHandler[\"JPK Handler\"]:::core TOPOHandler[\"TopoStats Handler\"]:::core GWYHandler[\"GWY Handler\"]:::core end end %% Testing Layer subgraph Testing IOTest[\"IO Tests\"]:::test ASDTest[\"ASD Tests\"]:::test IBWTest[\"IBW Tests\"]:::test SPMTest[\"SPM Tests\"]:::test JPKTest[\"JPK Tests\"]:::test TOPOTest[\"TopoStats Tests\"]:::test GWYTest[\"GWY Tests\"]:::test end %% Development Tools subgraph DevTools PreCommit[\"Pre-commit Config\"]:::tools Pylint[\"Pylint Config\"]:::tools end %% Output Layer Output[\"Standardized Data Format\\n- Image Data\\n- Scaling Factor\\n- Metadata\"]:::output %% Relationships ASD --> ASDHandler IBW --> IBWHandler SPM --> SPMHandler JPK --> JPKHandler TOPO --> TOPOHandler GWY --> GWYHandler ASDHandler --> IO IBWHandler --> IO SPMHandler --> IO JPKHandler --> IO TOPOHandler --> IO GWYHandler --> IO IO < --> LOG IO --> Output ASDHandler --- ASDTest IBWHandler --- IBWTest SPMHandler --- SPMTest JPKHandler --- JPKTest TOPOHandler --- TOPOTest GWYHandler --- GWYTest IO --- IOTest %% Click Events click IO \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/io.py\" click LOG \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/logging.py\" click ASDHandler \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/asd.py\" click IBWHandler \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/ibw.py\" click SPMHandler \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/spm.py\" click JPKHandler \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/jpk.py\" click TOPOHandler \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/topostats.py\" click GWYHandler \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/gwy.py\" click ASDTest \"https://github.com/AFM-SPM/AFMReader/blob/main/tests/test_asd.py\" click IBWTest \"https://github.com/AFM-SPM/AFMReader/blob/main/tests/test_ibw.py\" click SPMTest \"https://github.com/AFM-SPM/AFMReader/blob/main/tests/test_spm.py\" click JPKTest \"https://github.com/AFM-SPM/AFMReader/blob/main/tests/test_jpk.py\" click TOPOTest \"https://github.com/AFM-SPM/AFMReader/blob/main/tests/test_topostats.py\" click GWYTest \"https://github.com/AFM-SPM/AFMReader/blob/main/tests/test_gwy.py\" click IOTest \"https://github.com/AFM-SPM/AFMReader/blob/main/tests/test_io.py\" click PreCommit \"https://github.com/AFM-SPM/AFMReader/blob/main/.pre-commit-config.yaml\" click Pylint \"https://github.com/AFM-SPM/AFMReader/blob/main/.pylintrc\" Generated using GitDiagram","title":"Workflow"},{"location":"workflow/#workflow","text":"flowchart TB %% Styles classDef input fill:#b3d9ff,stroke:#333,stroke-width:2px classDef core fill:#90EE90,stroke:#333,stroke-width:2px classDef output fill:#FFB366,stroke:#333,stroke-width:2px classDef test fill:#E6E6FA,stroke:#333,stroke-width:2px classDef tools fill:#FFE4B5,stroke:#333,stroke-width:2px %% Input Layer subgraph InputFormats ASD[\".asd Files\"]:::input IBW[\".ibw Files\"]:::input SPM[\".spm Files\"]:::input JPK[\".jpk Files\"]:::input TOPO[\".topostats Files\"]:::input GWY[\".gwy Files\"]:::input end %% Core Processing Layer subgraph CoreProcessing IO[\"IO Module\\n(Base Reader)\"]:::core LOG[\"Logging Module\"]:::core subgraph FormatHandlers ASDHandler[\"ASD Handler\"]:::core IBWHandler[\"IBW Handler\"]:::core SPMHandler[\"SPM Handler\"]:::core JPKHandler[\"JPK Handler\"]:::core TOPOHandler[\"TopoStats Handler\"]:::core GWYHandler[\"GWY Handler\"]:::core end end %% Testing Layer subgraph Testing IOTest[\"IO Tests\"]:::test ASDTest[\"ASD Tests\"]:::test IBWTest[\"IBW Tests\"]:::test SPMTest[\"SPM Tests\"]:::test JPKTest[\"JPK Tests\"]:::test TOPOTest[\"TopoStats Tests\"]:::test GWYTest[\"GWY Tests\"]:::test end %% Development Tools subgraph DevTools PreCommit[\"Pre-commit Config\"]:::tools Pylint[\"Pylint Config\"]:::tools end %% Output Layer Output[\"Standardized Data Format\\n- Image Data\\n- Scaling Factor\\n- Metadata\"]:::output %% Relationships ASD --> ASDHandler IBW --> IBWHandler SPM --> SPMHandler JPK --> JPKHandler TOPO --> TOPOHandler GWY --> GWYHandler ASDHandler --> IO IBWHandler --> IO SPMHandler --> IO JPKHandler --> IO TOPOHandler --> IO GWYHandler --> IO IO < --> LOG IO --> Output ASDHandler --- ASDTest IBWHandler --- IBWTest SPMHandler --- SPMTest JPKHandler --- JPKTest TOPOHandler --- TOPOTest GWYHandler --- GWYTest IO --- IOTest %% Click Events click IO \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/io.py\" click LOG \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/logging.py\" click ASDHandler \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/asd.py\" click IBWHandler \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/ibw.py\" click SPMHandler \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/spm.py\" click JPKHandler \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/jpk.py\" click TOPOHandler \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/topostats.py\" click GWYHandler \"https://github.com/AFM-SPM/AFMReader/blob/main/AFMReader/gwy.py\" click ASDTest \"https://github.com/AFM-SPM/AFMReader/blob/main/tests/test_asd.py\" click IBWTest \"https://github.com/AFM-SPM/AFMReader/blob/main/tests/test_ibw.py\" click SPMTest \"https://github.com/AFM-SPM/AFMReader/blob/main/tests/test_spm.py\" click JPKTest \"https://github.com/AFM-SPM/AFMReader/blob/main/tests/test_jpk.py\" click TOPOTest \"https://github.com/AFM-SPM/AFMReader/blob/main/tests/test_topostats.py\" click GWYTest \"https://github.com/AFM-SPM/AFMReader/blob/main/tests/test_gwy.py\" click IOTest \"https://github.com/AFM-SPM/AFMReader/blob/main/tests/test_io.py\" click PreCommit \"https://github.com/AFM-SPM/AFMReader/blob/main/.pre-commit-config.yaml\" click Pylint \"https://github.com/AFM-SPM/AFMReader/blob/main/.pylintrc\" Generated using GitDiagram","title":"Workflow"},{"location":"api/asd/","text":"ASD Modules For decoding and loading .asd AFM file format into Python Numpy arrays. BipolarConverter Bases: VoltageLevelConverter A VoltageLevelConverter for bipolar encodings. (-X to +X Volts). Source code in AFMReader/asd.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 class BipolarConverter ( VoltageLevelConverter ): \"\"\"A VoltageLevelConverter for bipolar encodings. (-X to +X Volts).\"\"\" def level_to_voltage ( self : Self , level : float ) -> float : \"\"\" Calculate the real world height scale in nanometres for an arbitrary level value. Parameters ---------- level : float Arbitrary height measurement from the AFM that needs converting into real world length scale units. Returns ------- float Real world nanometre height for the input height level. \"\"\" return ( self . ad_range - 2 * level * self . ad_range / self . resolution ) * self . scaling_factor level_to_voltage ( level ) Calculate the real world height scale in nanometres for an arbitrary level value. Parameters: Name Type Description Default level float Arbitrary height measurement from the AFM that needs converting into real world length scale units. required Returns: Type Description float Real world nanometre height for the input height level. Source code in AFMReader/asd.py 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def level_to_voltage ( self : Self , level : float ) -> float : \"\"\" Calculate the real world height scale in nanometres for an arbitrary level value. Parameters ---------- level : float Arbitrary height measurement from the AFM that needs converting into real world length scale units. Returns ------- float Real world nanometre height for the input height level. \"\"\" return ( self . ad_range - 2 * level * self . ad_range / self . resolution ) * self . scaling_factor UnipolarConverter Bases: VoltageLevelConverter A VoltageLevelConverter for unipolar encodings. (0 to +X Volts). Source code in AFMReader/asd.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 class UnipolarConverter ( VoltageLevelConverter ): \"\"\"A VoltageLevelConverter for unipolar encodings. (0 to +X Volts).\"\"\" def level_to_voltage ( self : Self , level : float ) -> float : \"\"\" Calculate the real world height scale in nanometres for an arbitrary level value. Parameters ---------- level : float Arbitrary height measurement from the AFM that needs converting into real world length scale units. Returns ------- float Real world nanometre height for the input height level. \"\"\" multiplier = - self . ad_range / self . resolution * self . scaling_factor return level * multiplier level_to_voltage ( level ) Calculate the real world height scale in nanometres for an arbitrary level value. Parameters: Name Type Description Default level float Arbitrary height measurement from the AFM that needs converting into real world length scale units. required Returns: Type Description float Real world nanometre height for the input height level. Source code in AFMReader/asd.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 def level_to_voltage ( self : Self , level : float ) -> float : \"\"\" Calculate the real world height scale in nanometres for an arbitrary level value. Parameters ---------- level : float Arbitrary height measurement from the AFM that needs converting into real world length scale units. Returns ------- float Real world nanometre height for the input height level. \"\"\" multiplier = - self . ad_range / self . resolution * self . scaling_factor return level * multiplier VoltageLevelConverter A class for converting arbitrary height levels from the AFM into real world nanometre heights. Different .asd files require different functions to perform this calculation based on many factors, hence why we need to define the correct function in each case. Parameters: Name Type Description Default analogue_digital_range float The range of analogue voltage values. required scaling_factor float A scaling factor calculated elsewhere that scales the heightmap appropriately based on the type of channel and sensor parameters. required resolution int The vertical resolution of the instrument. Dependant on the number of bits used to store its values. Typically 12, hence 2^12 = 4096 sensitivity levels. required Source code in AFMReader/asd.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 class VoltageLevelConverter : \"\"\" A class for converting arbitrary height levels from the AFM into real world nanometre heights. Different .asd files require different functions to perform this calculation based on many factors, hence why we need to define the correct function in each case. Parameters ---------- analogue_digital_range : float The range of analogue voltage values. scaling_factor : float A scaling factor calculated elsewhere that scales the heightmap appropriately based on the type of channel and sensor parameters. resolution : int The vertical resolution of the instrument. Dependant on the number of bits used to store its values. Typically 12, hence 2^12 = 4096 sensitivity levels. \"\"\" def __init__ ( self : Self , analogue_digital_range : float , scaling_factor : float , resolution : int ) -> None : \"\"\" Convert arbitrary height levels from the AFM into real world nanometre heights. Parameters ---------- analogue_digital_range : float The range of analogue voltage values. scaling_factor : float A scaling factor calculated elsewhere that scales the heightmap appropriately based on the type of channel and sensor parameters. resolution : int The vertical resolution of the instrumen. Dependant on the number of bits used to store its values. Typically 12, hence 2^12 = 4096 sensitivity levels. \"\"\" self . ad_range = analogue_digital_range self . scaling_factor = scaling_factor self . resolution = resolution logger . info ( f \"created voltage converter. ad_range: { analogue_digital_range } -> { self . ad_range } , \" f \" scaling factor: { scaling_factor } , resolution: { resolution } \" ) __init__ ( analogue_digital_range , scaling_factor , resolution ) Convert arbitrary height levels from the AFM into real world nanometre heights. Parameters: Name Type Description Default analogue_digital_range float The range of analogue voltage values. required scaling_factor float A scaling factor calculated elsewhere that scales the heightmap appropriately based on the type of channel and sensor parameters. required resolution int The vertical resolution of the instrumen. Dependant on the number of bits used to store its values. Typically 12, hence 2^12 = 4096 sensitivity levels. required Source code in AFMReader/asd.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def __init__ ( self : Self , analogue_digital_range : float , scaling_factor : float , resolution : int ) -> None : \"\"\" Convert arbitrary height levels from the AFM into real world nanometre heights. Parameters ---------- analogue_digital_range : float The range of analogue voltage values. scaling_factor : float A scaling factor calculated elsewhere that scales the heightmap appropriately based on the type of channel and sensor parameters. resolution : int The vertical resolution of the instrumen. Dependant on the number of bits used to store its values. Typically 12, hence 2^12 = 4096 sensitivity levels. \"\"\" self . ad_range = analogue_digital_range self . scaling_factor = scaling_factor self . resolution = resolution logger . info ( f \"created voltage converter. ad_range: { analogue_digital_range } -> { self . ad_range } , \" f \" scaling factor: { scaling_factor } , resolution: { resolution } \" ) calculate_scaling_factor ( channel , z_piezo_gain , z_piezo_extension , scanner_sensitivity , phase_sensitivity ) Calculate the correct scaling factor. This function should be used in conjunction with the VoltageLevelConverter class to define the correct function and enables conversion between arbitrary level values from the AFM into real world nanometre height values. Parameters: Name Type Description Default channel str The .asd channel being used. required z_piezo_gain float The z_piezo_gain listed in the header metadata for the .asd file. required z_piezo_extension float The z_piezo_extension listed in the header metadata for the .asd file. required scanner_sensitivity float The scanner_sensitivity listed in the header metadata for the .asd file. required phase_sensitivity float The phase_sensitivity listed in the heder metadata for the .asd file. required Returns: Type Description float The appropriate scaling factor to pass to a VoltageLevelConverter to convert arbitrary height levels to real world nanometre heights for the frame data in the specified channl in the .asd file. Source code in AFMReader/asd.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def calculate_scaling_factor ( channel : str , z_piezo_gain : float , z_piezo_extension : float , scanner_sensitivity : float , phase_sensitivity : float , ) -> float : \"\"\" Calculate the correct scaling factor. This function should be used in conjunction with the VoltageLevelConverter class to define the correct function and enables conversion between arbitrary level values from the AFM into real world nanometre height values. Parameters ---------- channel : str The .asd channel being used. z_piezo_gain : float The z_piezo_gain listed in the header metadata for the .asd file. z_piezo_extension : float The z_piezo_extension listed in the header metadata for the .asd file. scanner_sensitivity : float The scanner_sensitivity listed in the header metadata for the .asd file. phase_sensitivity : float The phase_sensitivity listed in the heder metadata for the .asd file. Returns ------- float The appropriate scaling factor to pass to a VoltageLevelConverter to convert arbitrary height levels to real world nanometre heights for the frame data in the specified channl in the .asd file. \"\"\" if channel == \"TP\" : logger . info ( f \"Scaling factor: Type: { channel } -> TP | piezo extension { z_piezo_gain } \" f \"* piezo gain { z_piezo_extension } = scaling factor { z_piezo_gain * z_piezo_extension } \" ) return z_piezo_gain * z_piezo_extension if channel == \"ER\" : logger . info ( f \"Scaling factor: Type: { channel } -> ER | - scanner sensitivity { - scanner_sensitivity } \" f \"= scaling factor { - scanner_sensitivity } \" ) return - scanner_sensitivity if channel == \"PH\" : logger . info ( f \"Scaling factor: Type: { channel } -> PH | - phase sensitivity { - phase_sensitivity } \" f \"= scaling factor { - phase_sensitivity } \" ) return - phase_sensitivity raise ValueError ( f \"channel { channel } not known for .asd file type.\" ) create_analogue_digital_converter ( analogue_digital_range , scaling_factor , resolution = 4096 ) Create an analogue to digital converter for a given range, scaling factor and resolution. Used for converting raw level values into real world height scales in nanometres. Parameters: Name Type Description Default analogue_digital_range float The range of analogue voltage values. required scaling_factor float A scaling factor calculated elsewhere that scales the heightmap appropriately based on the type of channel and sensor parameters. required resolution int The vertical resolution of the instrumen. Dependant on the number of bits used to store its values. Typically 12, hence 2^12 = 4096 sensitivity levels. 4096 Returns: Type Description VoltageLevelConverter An instance of the VoltageLevelConverter class with a tailored function level_to_voltage which converts arbitrary level values into real world nanometre heights for the given .asd file. Note that this is file specific since the parameters will change between files. Source code in AFMReader/asd.py 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 def create_analogue_digital_converter ( analogue_digital_range : float , scaling_factor : float , resolution : int = 4096 ) -> VoltageLevelConverter : \"\"\" Create an analogue to digital converter for a given range, scaling factor and resolution. Used for converting raw level values into real world height scales in nanometres. Parameters ---------- analogue_digital_range : float The range of analogue voltage values. scaling_factor : float A scaling factor calculated elsewhere that scales the heightmap appropriately based on the type of channel and sensor parameters. resolution : int The vertical resolution of the instrumen. Dependant on the number of bits used to store its values. Typically 12, hence 2^12 = 4096 sensitivity levels. Returns ------- VoltageLevelConverter An instance of the VoltageLevelConverter class with a tailored function `level_to_voltage` which converts arbitrary level values into real world nanometre heights for the given .asd file. Note that this is file specific since the parameters will change between files. \"\"\" # Analogue to digital hex conversion range encoding: # unipolar_1_00V : 0x00000001 +0.00 to +1.00 V # unipolar_2_50V : 0x00000002 +0.00 to +2.50 V # unipolar_9.99v : 0x00000003 +0.00 to +9.99 V # unipolar_5_00V : 0x00000004 +0.00 to +5.00 V # bipolar_1_00V : 0x00010000 -1.00 to +1.00 V # bipolar_2_50V : 0x00020000 -2.50 to +2.50 V # bipolar_5_00V : 0x00040000 -5.00 to +5.00 V converter : VoltageLevelConverter if analogue_digital_range == hex ( 0x00000001 ): # unipolar 1.0V mapping = ( 0.0 , 1.0 ) converter = UnipolarConverter ( analogue_digital_range = 1.0 , resolution = resolution , scaling_factor = scaling_factor , ) elif analogue_digital_range == hex ( 0x00000002 ): # unipolar 2.5V mapping = ( 0.0 , 2.5 ) converter = UnipolarConverter ( analogue_digital_range = 2.5 , resolution = resolution , scaling_factor = scaling_factor , ) elif analogue_digital_range == hex ( 0x00000003 ): mapping = ( 0 , 9.99 ) converter = UnipolarConverter ( analogue_digital_range = 9.99 , resolution = resolution , scaling_factor = scaling_factor , ) elif analogue_digital_range == hex ( 0x00000004 ): # unipolar 5.0V mapping = ( 0.0 , 5.0 ) converter = UnipolarConverter ( analogue_digital_range = 5.0 , resolution = resolution , scaling_factor = scaling_factor , ) elif analogue_digital_range == hex ( 0x00010000 ): # bipolar 1.0V mapping = ( - 1.0 , 1.0 ) converter = BipolarConverter ( analogue_digital_range = 1.0 , resolution = resolution , scaling_factor = scaling_factor , ) elif analogue_digital_range == hex ( 0x00020000 ): # bipolar 2.5V mapping = ( - 2.5 , 2.5 ) converter = BipolarConverter ( analogue_digital_range = 2.5 , resolution = resolution , scaling_factor = scaling_factor , ) elif analogue_digital_range == hex ( 0x00040000 ): # bipolar 5.0V mapping = ( - 5.0 , 5.0 ) converter = BipolarConverter ( analogue_digital_range = 5.0 , resolution = resolution , scaling_factor = scaling_factor , ) else : raise ValueError ( f \"Analogue to digital range hex value { analogue_digital_range } has no known \" \"analogue-digital mapping.\" ) logger . info ( f \"Analogue to digital mapping | Range: { analogue_digital_range } -> { mapping } \" ) logger . info ( f \"Converter: { converter } \" ) return converter create_animation ( file_name , frames , file_format = '.gif' ) Create animation from a numpy array of frames (2d numpy arrays). File format can be specified, defaults to .gif. Parameters: Name Type Description Default file_name str Name of the file to save. required frames NDArray Numpy array of frames of shape (N x W x H) where N is the number of frames, W is the width of the frames and H is the height of the frames. required file_format str Optional string for the file format to save as. Formats currently available: .mp4, .gif. '.gif' Source code in AFMReader/asd.py 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 def create_animation ( file_name : str , frames : npt . NDArray , file_format : str = \".gif\" ) -> None : \"\"\" Create animation from a numpy array of frames (2d numpy arrays). File format can be specified, defaults to .gif. Parameters ---------- file_name : str Name of the file to save. frames : npt.NDArray Numpy array of frames of shape (N x W x H) where N is the number of frames, W is the width of the frames and H is the height of the frames. file_format : str Optional string for the file format to save as. Formats currently available: .mp4, .gif. \"\"\" fig , axis = plt . subplots () def update ( frame : npt . NDArray ): \"\"\" Update the image with the latest frame. Parameters ---------- frame : npt.NDArray Single frame to add to the image. Returns ------- axis Matplotlib axis. \"\"\" axis . imshow ( frames [ frame ]) return axis # Create the animation object ani = animation . FuncAnimation ( fig , update , frames = frames . shape [ 0 ], interval = 200 ) if file_format == \".mp4\" : ani . save ( f \" { file_name } .mp4\" , writer = \"ffmpeg\" ) elif file_format == \".gif\" : ani . save ( f \" { file_name } .gif\" , writer = \"imagemagick\" ) else : raise ValueError ( f \" { file_format } format not supported yet.\" ) load_asd ( file_path , channel ) Load a .asd file. Parameters: Name Type Description Default file_path Path Path to the .asd file. required channel str Channel to load. Note that only three channels seem to be present in a single .asd file. Options: TP (Topograph), ER (Error) and PH (Phase). required Returns: Type Description NDArray The .asd file frames data as a numpy 3D array N x W x H (Number of frames x Width of each frame x height of each frame). float The number of nanometres per pixel for the .asd file. (AKA the resolution). Enables converting between pixels and nanometres when working with the data, in order to use real-world length scales. dict Metadata for the .asd file. The number of entries is too long to list here, and changes based on the file version please either look into the read_header_file_version_x functions or print the keys too see what metadata is available. Source code in AFMReader/asd.py 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 def load_asd ( file_path : str | Path , channel : str ): \"\"\" Load a .asd file. Parameters ---------- file_path : Path Path to the .asd file. channel : str Channel to load. Note that only three channels seem to be present in a single .asd file. Options: TP (Topograph), ER (Error) and PH (Phase). Returns ------- npt.NDArray The .asd file frames data as a numpy 3D array N x W x H (Number of frames x Width of each frame x height of each frame). float The number of nanometres per pixel for the .asd file. (AKA the resolution). Enables converting between pixels and nanometres when working with the data, in order to use real-world length scales. dict Metadata for the .asd file. The number of entries is too long to list here, and changes based on the file version please either look into the `read_header_file_version_x` functions or print the keys too see what metadata is available. \"\"\" # Ensure the file path is a Path object file_path = Path ( file_path ) filename = file_path . stem # Check the file exists and raise an error if not if not file_path . is_file (): logger . error ( f \"[ { filename } ] File not found : { file_path } \" ) raise FileNotFoundError ( errno . ENOENT , os . strerror ( errno . ENOENT ), file_path ) # Open the file in binary mode with Path . open ( file_path , \"rb\" , encoding = None ) as open_file : # pylint: disable=unspecified-encoding file_version = read_file_version ( open_file ) if file_version == 0 : header_dict = read_header_file_version_0 ( open_file ) elif file_version == 1 : header_dict = read_header_file_version_1 ( open_file ) elif file_version == 2 : header_dict = read_header_file_version_2 ( open_file ) else : raise ValueError ( f \"File version { file_version } unknown. Please add support if you \" \"know how to decode this file version.\" ) logger . debug ( f \"header dict: \\n { header_dict } \" ) pixel_to_nanometre_scaling_factor_x = header_dict [ \"x_nm\" ] / header_dict [ \"x_pixels\" ] pixel_to_nanometre_scaling_factor_y = header_dict [ \"y_nm\" ] / header_dict [ \"y_pixels\" ] if pixel_to_nanometre_scaling_factor_x != pixel_to_nanometre_scaling_factor_y : logger . warning ( f \"Resolution of image is different in x and y directions:\" f \"x: { pixel_to_nanometre_scaling_factor_x } \" f \"y: { pixel_to_nanometre_scaling_factor_y } \" ) pixel_to_nanometre_scaling_factor = pixel_to_nanometre_scaling_factor_x if channel == header_dict [ \"channel1\" ]: logger . info ( f \"Requested channel { channel } matches first channel in file: { header_dict [ 'channel1' ] } \" ) elif channel == header_dict [ \"channel2\" ]: logger . info ( f \"Requested channel { channel } matches second channel in file: \" f \" { header_dict [ 'channel2' ] } \" ) # Skip first channel data _size_of_frame_header = header_dict [ \"frame_header_length\" ] # Remember that each value is two bytes (since signed int16) size_of_single_frame_plus_header = ( header_dict [ \"frame_header_length\" ] + header_dict [ \"x_pixels\" ] * header_dict [ \"y_pixels\" ] * 2 ) length_of_all_first_channel_frames = header_dict [ \"num_frames\" ] * size_of_single_frame_plus_header _ = open_file . read ( length_of_all_first_channel_frames ) else : raise ValueError ( f \"Channel { channel } not found in this file's available channels: \" f \" { header_dict [ 'channel1' ] } , { header_dict [ 'channel2' ] } \" ) scaling_factor = calculate_scaling_factor ( channel = channel , z_piezo_gain = header_dict [ \"z_piezo_gain\" ], z_piezo_extension = header_dict [ \"z_piezo_extension\" ], scanner_sensitivity = header_dict [ \"scanner_sensitivity\" ], phase_sensitivity = header_dict [ \"phase_sensitivity\" ], ) analogue_digital_converter = create_analogue_digital_converter ( analogue_digital_range = header_dict [ \"analogue_digital_range\" ], scaling_factor = scaling_factor , ) frames = read_channel_data ( open_file = open_file , num_frames = header_dict [ \"num_frames\" ], x_pixels = header_dict [ \"x_pixels\" ], y_pixels = header_dict [ \"y_pixels\" ], analogue_digital_converter = analogue_digital_converter , ) frames = np . array ( frames ) return frames , pixel_to_nanometre_scaling_factor , header_dict read_channel_data ( open_file , num_frames , x_pixels , y_pixels , analogue_digital_converter ) Read frame data from an open .asd file, starting at the current position. Parameters: Name Type Description Default open_file BinaryIO An open binary file object for a .asd file. required num_frames int The number of frames for this set of frame data. required x_pixels int The width of each frame in pixels. required y_pixels int The height of each frame in pixels. required analogue_digital_converter VoltageLevelConverter A VoltageLevelConverter instance for converting the raw level values to real world nanometre vertical heights. required Returns: Type Description ndarray The extracted frame heightmap data as a N x W x H 3D numpy array (number of frames x width of each frame x height of each frame). Units are nanometres. Source code in AFMReader/asd.py 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 def read_channel_data ( open_file : BinaryIO , num_frames : int , x_pixels : int , y_pixels : int , analogue_digital_converter : VoltageLevelConverter , ) -> npt . NDArray : \"\"\" Read frame data from an open .asd file, starting at the current position. Parameters ---------- open_file : BinaryIO An open binary file object for a .asd file. num_frames : int The number of frames for this set of frame data. x_pixels : int The width of each frame in pixels. y_pixels : int The height of each frame in pixels. analogue_digital_converter : VoltageLevelConverter A VoltageLevelConverter instance for converting the raw level values to real world nanometre vertical heights. Returns ------- np.ndarray The extracted frame heightmap data as a N x W x H 3D numpy array (number of frames x width of each frame x height of each frame). Units are nanometres. \"\"\" # List to store the frames as numpy arrays frames = [] # Dictionary to store all the variables together in case we want to return them. # Very useful for debugging! frame_header_dict = {} for _ in range ( num_frames ): frame_header_dict [ \"frame_number\" ] = read_int32 ( open_file ) frame_header_dict [ \"max_data\" ] = read_int16 ( open_file ) frame_header_dict [ \"min_data\" ] = read_int16 ( open_file ) frame_header_dict [ \"x_offset\" ] = read_int16 ( open_file ) frame_header_dict [ \"y_offset\" ] = read_int16 ( open_file ) frame_header_dict [ \"x_tilt\" ] = read_float ( open_file ) frame_header_dict [ \"y_tilt\" ] = read_float ( open_file ) frame_header_dict [ \"is_stimulated\" ] = read_bool ( open_file ) _booked_1 = read_int8 ( open_file ) _booked_2 = read_int16 ( open_file ) _booked_3 = read_int32 ( open_file ) _booked_4 = read_int32 ( open_file ) frame_header_dict [ \"total_size\" ] = x_pixels * y_pixels # Read frame byte data. Data is always stored as signed 2 byte integer form # so multiply the size of the array by 2 frame_header_dict [ \"total_byte_size\" ] = frame_header_dict [ \"total_size\" ] * 2 frame_data = open_file . read ( frame_header_dict [ \"total_size\" ] * 2 ) # Decode frame data from bytes. Data is always stored in signed 2 byte integer form frame_data = np . frombuffer ( frame_data , dtype = np . int16 ) # Convert from Voltage to Real units frame_data = analogue_digital_converter . level_to_voltage ( frame_data ) # type: ignore # Reshape frame to 2D array frame_data = frame_data . reshape (( y_pixels , x_pixels )) # type: ignore frames . append ( frame_data ) return frames read_file_version ( open_file ) Read the file version from an open asd file. File versions are 0, 1 and 2. Different file versions require different functions to read the headers as the formatting changes between them. Parameters: Name Type Description Default open_file BinaryIO An open binary file object for a .asd file. required Returns: Type Description int Integer file version decoded from file. Source code in AFMReader/asd.py 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 def read_file_version ( open_file : BinaryIO ) -> int : \"\"\" Read the file version from an open asd file. File versions are 0, 1 and 2. Different file versions require different functions to read the headers as the formatting changes between them. Parameters ---------- open_file : BinaryIO An open binary file object for a .asd file. Returns ------- int Integer file version decoded from file. \"\"\" file_version = read_int32 ( open_file ) logger . info ( f \"file version: { file_version } \" ) return file_version read_header_file_version_0 ( open_file ) Read the header metadata for a .asd file using file version 0. Parameters: Name Type Description Default open_file BinaryIO An open binary file object for a .asd file. required Returns: Type Description dict Dictionary of metadata decoded from the file header. Source code in AFMReader/asd.py 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 def read_header_file_version_0 ( open_file : BinaryIO ) -> dict : \"\"\" Read the header metadata for a .asd file using file version 0. Parameters ---------- open_file : BinaryIO An open binary file object for a .asd file. Returns ------- dict Dictionary of metadata decoded from the file header. \"\"\" header_dict : dict [ str , Any ] = {} # There only ever seem to be two channels available # Channel encoding are all in LITTLE ENDIAN format. # topology: 0x5054 decodes to 'TP' in ascii little endian # error: 0x5245 decodes to 'ER' in ascii little endian # phase: 0x4850 decodes to 'PH' in ascii little endian header_dict [ \"channel1\" ] = read_ascii ( open_file , 2 ) header_dict [ \"channel2\" ] = read_ascii ( open_file , 2 ) # length of file metadata header in bytes - so we can skip it to get to the data header_dict [ \"header_length\" ] = read_int32 ( open_file ) # Frame header is the length of the header for each frame to be skipped # before reading frame data. header_dict [ \"frame_header_length\" ] = read_int32 ( open_file ) # Length in bytes of the name given in the file header_dict [ \"user_name_size\" ] = read_int32 ( open_file ) header_dict [ \"comment_offset_size\" ] = read_int32 ( open_file ) # Length in bytes of the comment for the file header_dict [ \"comment_size\" ] = read_int32 ( open_file ) # x and y resolution (pixels) header_dict [ \"x_pixels\" ] = read_int16 ( open_file ) header_dict [ \"y_pixels\" ] = read_int16 ( open_file ) # x and y resolution (nm) header_dict [ \"x_nm\" ] = read_int16 ( open_file ) header_dict [ \"y_nm\" ] = read_int16 ( open_file ) # frame time header_dict [ \"frame_time\" ] = read_float ( open_file ) # z piezo extension header_dict [ \"z_piezo_extension\" ] = read_float ( open_file ) # z piezo gain header_dict [ \"z_piezo_gain\" ] = read_float ( open_file ) # Range of analogue voltage values (for conversion to digital) header_dict [ \"analogue_digital_range\" ] = read_hex_u32 ( open_file ) # Number of bits of data for analogue voltage values (for conversion to digital) # aka the resolution of the instrument. Usually 12 bits, so 4096 sensitivity levels header_dict [ \"analogue_digital_data_bits_size\" ] = read_int32 ( open_file ) header_dict [ \"analogue_digital_resolution\" ] = 2 ^ header_dict [ \"analogue_digital_data_bits_size\" ] # Not sure, something to do with data averaging header_dict [ \"is_averaged\" ] = read_bool ( open_file ) # Window for averaging the data header_dict [ \"averaging_window\" ] = read_int32 ( open_file ) # Some padding to ensure backwards compatilibilty I think _ = read_int16 ( open_file ) # Date of creation header_dict [ \"year\" ] = read_int16 ( open_file ) header_dict [ \"month\" ] = read_uint8 ( open_file ) header_dict [ \"day\" ] = read_uint8 ( open_file ) header_dict [ \"hour\" ] = read_uint8 ( open_file ) header_dict [ \"minute\" ] = read_uint8 ( open_file ) header_dict [ \"second\" ] = read_uint8 ( open_file ) # Rounding degree? header_dict [ \"rounding_degree\" ] = read_uint8 ( open_file ) # Maximum x and y scanning range in real space, nm header_dict [ \"max_x_scan_range\" ] = read_float ( open_file ) header_dict [ \"max_y_scan_range\" ] = read_float ( open_file ) # No idea _ = read_int32 ( open_file ) _ = read_int32 ( open_file ) _ = read_int32 ( open_file ) # Number of frames the file had when recorded header_dict [ \"initial_frames\" ] = read_int32 ( open_file ) # Actual number of frames header_dict [ \"num_frames\" ] = read_int32 ( open_file ) # ID of the AFM instrument header_dict [ \"afm_id\" ] = read_int32 ( open_file ) # ID of the file header_dict [ \"file_id\" ] = read_int16 ( open_file ) # Name of the user header_dict [ \"user_name\" ] = read_null_separated_utf8 ( open_file , length_bytes = header_dict [ \"user_name_size\" ]) # Sensitivity of the scanner in nm / V header_dict [ \"scanner_sensitivity\" ] = read_float ( open_file ) # Phase sensitivity header_dict [ \"phase_sensitivity\" ] = read_float ( open_file ) # Direction of the scan header_dict [ \"scan_direction\" ] = read_int32 ( open_file ) # Skip bytes: comment offset size _ = skip_bytes ( open_file , header_dict [ \"comment_offset_size\" ]) # Read a comment comment = [] for _ in range ( header_dict [ \"comment_size\" ]): comment . append ( chr ( read_int8 ( open_file ))) header_dict [ \"comment_without_null\" ] = \"\" . join ([ c for c in comment if c != \" \\x00 \" ]) return header_dict read_header_file_version_1 ( open_file ) Read the header metadata for a .asd file using file version 1. Parameters: Name Type Description Default open_file BinaryIO An open binary file object for a .asd file. required Returns: Type Description dict Dictionary of metadata decoded from the file header. Source code in AFMReader/asd.py 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 def read_header_file_version_1 ( open_file : BinaryIO ) -> dict [ str , int ]: \"\"\" Read the header metadata for a .asd file using file version 1. Parameters ---------- open_file : BinaryIO An open binary file object for a .asd file. Returns ------- dict Dictionary of metadata decoded from the file header. \"\"\" header_dict = {} # length of file metadata header in bytes - so we can skip it to get to the data header_dict [ \"header_length\" ] = read_int32 ( open_file ) # Frame header is the length of the header for each frame to be skipped before # reading frame data. header_dict [ \"frame_header_length\" ] = read_int32 ( open_file ) # Encoding for strings header_dict [ \"text_encoding\" ] = read_int32 ( open_file ) # Length in bytes of the name given in the file header_dict [ \"user_name_size\" ] = read_int32 ( open_file ) # Length in bytes of the comment for the file header_dict [ \"comment_size\" ] = read_int32 ( open_file ) # There only ever seem to be two channels available # Channel encoding are all in LITTLE ENDIAN format. # topology: 0x5054 decodes to 'TP' in ascii little endian # error: 0x5245 decodes to 'ER' in ascii little endian # phase: 0x4850 decodes to 'PH' in ascii little endian header_dict [ \"channel1\" ] = read_null_separated_utf8 ( open_file , length_bytes = 4 ) header_dict [ \"channel2\" ] = read_null_separated_utf8 ( open_file , length_bytes = 4 ) # Number of frames the file had when recorded header_dict [ \"initial_frames\" ] = read_int32 ( open_file ) # Actual number of frames header_dict [ \"num_frames\" ] = read_int32 ( open_file ) # Direction of the scan header_dict [ \"scan_direction\" ] = read_int32 ( open_file ) # ID of the file header_dict [ \"file_id\" ] = read_int32 ( open_file ) # x and y resolution (pixels) header_dict [ \"x_pixels\" ] = read_int32 ( open_file ) header_dict [ \"y_pixels\" ] = read_int32 ( open_file ) # x and y resolution (nm) header_dict [ \"x_nm\" ] = read_int32 ( open_file ) header_dict [ \"y_nm\" ] = read_int32 ( open_file ) # Not sure, something to do with data averaging header_dict [ \"is_averaged\" ] = read_bool ( open_file ) # Window for averaging the data header_dict [ \"averaging_window\" ] = read_int32 ( open_file ) # Date of creation header_dict [ \"year\" ] = read_int32 ( open_file ) header_dict [ \"month\" ] = read_int32 ( open_file ) header_dict [ \"day\" ] = read_int32 ( open_file ) header_dict [ \"hour\" ] = read_int32 ( open_file ) header_dict [ \"minute\" ] = read_int32 ( open_file ) header_dict [ \"second\" ] = read_int32 ( open_file ) # Rounding degree? header_dict [ \"x_rounding_degree\" ] = read_int32 ( open_file ) header_dict [ \"y_rounding_degree\" ] = read_int32 ( open_file ) # frame time header_dict [ \"frame_time\" ] = read_float ( open_file ) # Sensitivity of the scanner in nm / V header_dict [ \"scanner_sensitivity\" ] = read_float ( open_file ) # Phase sensitivity header_dict [ \"phase_sensitivity\" ] = read_float ( open_file ) # Offset? header_dict [ \"offset\" ] = read_int32 ( open_file ) # Ignore 12 bytes _ = skip_bytes ( open_file , 12 ) # ID of the AFM instrument header_dict [ \"afm_id\" ] = read_int32 ( open_file ) # Range of analogue voltage values (for conversion to digital) header_dict [ \"analogue_digital_range\" ] = read_hex_u32 ( open_file ) # Number of bits of data for analogue voltage values (for conversion to digital) # aka the resolution of the instrument. Usually 12 bits, so 4096 sensitivity levels header_dict [ \"analogue_digital_data_bits_size\" ] = read_int32 ( open_file ) header_dict [ \"analogue_digital_resolution\" ] = 2 ^ header_dict [ \"analogue_digital_data_bits_size\" ] # Maximum x and y scanning range in real space, nm header_dict [ \"max_x_scan_range\" ] = read_float ( open_file ) header_dict [ \"max_y_scan_range\" ] = read_float ( open_file ) # Piezo extensions header_dict [ \"x_piezo_extension\" ] = read_float ( open_file ) header_dict [ \"y_piezo_extension\" ] = read_float ( open_file ) header_dict [ \"z_piezo_extension\" ] = read_float ( open_file ) # Piezo gain header_dict [ \"z_piezo_gain\" ] = read_float ( open_file ) # Read the user name user_name = [] for _ in range ( header_dict [ \"user_name_size\" ]): user_name . append ( chr ( read_int8 ( open_file ))) header_dict [ \"user_name\" ] = \"\" . join ([ c for c in user_name if c != \" \\x00 \" ]) # Read a comment comment = [] for _ in range ( header_dict [ \"comment_size\" ]): comment . append ( chr ( read_int8 ( open_file ))) header_dict [ \"comment_without_null\" ] = \"\" . join ([ c for c in comment if c != \" \\x00 \" ]) return header_dict read_header_file_version_2 ( open_file ) Read the header metadata for a .asd file using file version 2. Parameters: Name Type Description Default open_file BinaryIO An open binary file object for a .asd file. required Returns: Type Description dict Dictionary of metadata decoded from the file header. Source code in AFMReader/asd.py 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 def read_header_file_version_2 ( open_file : BinaryIO ) -> dict : \"\"\" Read the header metadata for a .asd file using file version 2. Parameters ---------- open_file : BinaryIO An open binary file object for a .asd file. Returns ------- dict Dictionary of metadata decoded from the file header. \"\"\" header_dict = {} # length of file metadata header in bytes - so we can skip it to get to the data header_dict [ \"header_length\" ] = read_int32 ( open_file ) # Frame header is the length of the header for each frame to be skipped before # reading frame data. header_dict [ \"frame_header_length\" ] = read_int32 ( open_file ) # Encoding for strings header_dict [ \"text_encoding\" ] = read_int32 ( open_file ) # Length in bytes of the name given in the file header_dict [ \"user_name_size\" ] = read_int32 ( open_file ) # Length in bytes of the comment for the file header_dict [ \"comment_size\" ] = read_int32 ( open_file ) # There only ever seem to be two channels available # Channel encoding are all in LITTLE ENDIAN format. # topology: 0x5054 decodes to 'TP' in ascii little endian # error: 0x5245 decodes to 'ER' in ascii little endian # phase: 0x4850 decodes to 'PH' in ascii little endian header_dict [ \"channel1\" ] = read_null_separated_utf8 ( open_file , length_bytes = 4 ) header_dict [ \"channel2\" ] = read_null_separated_utf8 ( open_file , length_bytes = 4 ) # Number of frames the file had when recorded header_dict [ \"initial_frames\" ] = read_int32 ( open_file ) # Actual number of frames header_dict [ \"num_frames\" ] = read_int32 ( open_file ) # Direction of the scan header_dict [ \"scan_direction\" ] = read_int32 ( open_file ) # ID of the file header_dict [ \"file_id\" ] = read_int32 ( open_file ) # x and y resolution (pixels) header_dict [ \"x_pixels\" ] = read_int32 ( open_file ) header_dict [ \"y_pixels\" ] = read_int32 ( open_file ) # x and y resolution (nm) header_dict [ \"x_nm\" ] = read_int32 ( open_file ) header_dict [ \"y_nm\" ] = read_int32 ( open_file ) # Not sure, something to do with data averaging header_dict [ \"is_averaged\" ] = read_bool ( open_file ) # Window for averaging the data header_dict [ \"averaging_window\" ] = read_int32 ( open_file ) # Date of creation header_dict [ \"year\" ] = read_int32 ( open_file ) header_dict [ \"month\" ] = read_int32 ( open_file ) header_dict [ \"day\" ] = read_int32 ( open_file ) header_dict [ \"hour\" ] = read_int32 ( open_file ) header_dict [ \"minute\" ] = read_int32 ( open_file ) header_dict [ \"second\" ] = read_int32 ( open_file ) # Rounding degree? header_dict [ \"x_rounding_degree\" ] = read_int32 ( open_file ) header_dict [ \"y_rounding_degree\" ] = read_int32 ( open_file ) # frame time header_dict [ \"frame_time\" ] = read_float ( open_file ) # Sensitivity of the scanner in nm / V header_dict [ \"scanner_sensitivity\" ] = read_float ( open_file ) # Phase sensitivity header_dict [ \"phase_sensitivity\" ] = read_float ( open_file ) # Offset? header_dict [ \"offset\" ] = read_int32 ( open_file ) # Ignore 12 bytes _ = skip_bytes ( open_file , 12 ) # ID of the AFM instrument header_dict [ \"afm_id\" ] = read_int32 ( open_file ) # Range of analogue voltage values (for conversion to digital) header_dict [ \"analogue_digital_range\" ] = read_hex_u32 ( open_file ) # Number of bits of data for analogue voltage values (for conversion to digital) # aka the resolution of the instrument. Usually 12 bits, so 4096 sensitivity levels header_dict [ \"analogue_digital_data_bits_size\" ] = read_int32 ( open_file ) header_dict [ \"analogue_digital_resolution\" ] = 2 ^ header_dict [ \"analogue_digital_data_bits_size\" ] # Maximum x and y scanning range in real space, nm header_dict [ \"max_x_scan_range\" ] = read_float ( open_file ) header_dict [ \"max_y_scan_range\" ] = read_float ( open_file ) # Piezo extensions header_dict [ \"x_piezo_extension\" ] = read_float ( open_file ) header_dict [ \"y_piezo_extension\" ] = read_float ( open_file ) header_dict [ \"z_piezo_extension\" ] = read_float ( open_file ) # Piezo gain header_dict [ \"z_piezo_gain\" ] = read_float ( open_file ) # Read the user name user_name = [] for _ in range ( header_dict [ \"user_name_size\" ]): user_name . append ( chr ( read_int8 ( open_file ))) header_dict [ \"user_name\" ] = \"\" . join ([ c for c in user_name if c != \" \\x00 \" ]) # Read a comment comment = [] for _ in range ( header_dict [ \"comment_size\" ]): comment . append ( chr ( read_int8 ( open_file ))) header_dict [ \"comment_without_null\" ] = \"\" . join ([ c for c in comment if c != \" \\x00 \" ]) # No idea why this file type has the number of frames again. Storing it just in case. header_dict [ \"number_of_frames\" ] = read_int32 ( open_file ) # Feed forward parameter, no idea what it does. header_dict [ \"is_x_feed_forward_integer\" ] = read_int32 ( open_file ) # Feed forward parameter, no idea what it does. header_dict [ \"is_x_feed_forward_double\" ] = read_double ( open_file ) # Minimum and maximum colour mapping values header_dict [ \"max_colour_scale\" ] = read_int32 ( open_file ) header_dict [ \"min_colour_scale\" ] = read_int32 ( open_file ) # RGB anchor point array sizes header_dict [ \"length_red_anchor_points\" ] = read_int32 ( open_file ) header_dict [ \"length_green_anchor_points\" ] = read_int32 ( open_file ) header_dict [ \"length_blue_anchor_points\" ] = read_int32 ( open_file ) # Coords of anchor points # Red coords_red = [] for _ in range ( header_dict [ \"length_red_anchor_points\" ]): anchor_x = read_int32 ( open_file ) anchor_y = read_int32 ( open_file ) coords_red . append (( anchor_x , anchor_y )) # Green coords_green = [] for _ in range ( header_dict [ \"length_green_anchor_points\" ]): anchor_x = read_int32 ( open_file ) anchor_y = read_int32 ( open_file ) coords_green . append (( anchor_x , anchor_y )) # Blue coords_blue = [] for _ in range ( header_dict [ \"length_blue_anchor_points\" ]): anchor_x = read_int32 ( open_file ) anchor_y = read_int32 ( open_file ) coords_blue . append (( anchor_x , anchor_y )) return header_dict","title":"ASD"},{"location":"api/asd/#asd-modules","text":"For decoding and loading .asd AFM file format into Python Numpy arrays.","title":"ASD Modules"},{"location":"api/asd/#AFMReader.asd.BipolarConverter","text":"Bases: VoltageLevelConverter A VoltageLevelConverter for bipolar encodings. (-X to +X Volts). Source code in AFMReader/asd.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 class BipolarConverter ( VoltageLevelConverter ): \"\"\"A VoltageLevelConverter for bipolar encodings. (-X to +X Volts).\"\"\" def level_to_voltage ( self : Self , level : float ) -> float : \"\"\" Calculate the real world height scale in nanometres for an arbitrary level value. Parameters ---------- level : float Arbitrary height measurement from the AFM that needs converting into real world length scale units. Returns ------- float Real world nanometre height for the input height level. \"\"\" return ( self . ad_range - 2 * level * self . ad_range / self . resolution ) * self . scaling_factor","title":"BipolarConverter"},{"location":"api/asd/#AFMReader.asd.BipolarConverter.level_to_voltage","text":"Calculate the real world height scale in nanometres for an arbitrary level value. Parameters: Name Type Description Default level float Arbitrary height measurement from the AFM that needs converting into real world length scale units. required Returns: Type Description float Real world nanometre height for the input height level. Source code in AFMReader/asd.py 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def level_to_voltage ( self : Self , level : float ) -> float : \"\"\" Calculate the real world height scale in nanometres for an arbitrary level value. Parameters ---------- level : float Arbitrary height measurement from the AFM that needs converting into real world length scale units. Returns ------- float Real world nanometre height for the input height level. \"\"\" return ( self . ad_range - 2 * level * self . ad_range / self . resolution ) * self . scaling_factor","title":"level_to_voltage"},{"location":"api/asd/#AFMReader.asd.UnipolarConverter","text":"Bases: VoltageLevelConverter A VoltageLevelConverter for unipolar encodings. (0 to +X Volts). Source code in AFMReader/asd.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 class UnipolarConverter ( VoltageLevelConverter ): \"\"\"A VoltageLevelConverter for unipolar encodings. (0 to +X Volts).\"\"\" def level_to_voltage ( self : Self , level : float ) -> float : \"\"\" Calculate the real world height scale in nanometres for an arbitrary level value. Parameters ---------- level : float Arbitrary height measurement from the AFM that needs converting into real world length scale units. Returns ------- float Real world nanometre height for the input height level. \"\"\" multiplier = - self . ad_range / self . resolution * self . scaling_factor return level * multiplier","title":"UnipolarConverter"},{"location":"api/asd/#AFMReader.asd.UnipolarConverter.level_to_voltage","text":"Calculate the real world height scale in nanometres for an arbitrary level value. Parameters: Name Type Description Default level float Arbitrary height measurement from the AFM that needs converting into real world length scale units. required Returns: Type Description float Real world nanometre height for the input height level. Source code in AFMReader/asd.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 def level_to_voltage ( self : Self , level : float ) -> float : \"\"\" Calculate the real world height scale in nanometres for an arbitrary level value. Parameters ---------- level : float Arbitrary height measurement from the AFM that needs converting into real world length scale units. Returns ------- float Real world nanometre height for the input height level. \"\"\" multiplier = - self . ad_range / self . resolution * self . scaling_factor return level * multiplier","title":"level_to_voltage"},{"location":"api/asd/#AFMReader.asd.VoltageLevelConverter","text":"A class for converting arbitrary height levels from the AFM into real world nanometre heights. Different .asd files require different functions to perform this calculation based on many factors, hence why we need to define the correct function in each case. Parameters: Name Type Description Default analogue_digital_range float The range of analogue voltage values. required scaling_factor float A scaling factor calculated elsewhere that scales the heightmap appropriately based on the type of channel and sensor parameters. required resolution int The vertical resolution of the instrument. Dependant on the number of bits used to store its values. Typically 12, hence 2^12 = 4096 sensitivity levels. required Source code in AFMReader/asd.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 class VoltageLevelConverter : \"\"\" A class for converting arbitrary height levels from the AFM into real world nanometre heights. Different .asd files require different functions to perform this calculation based on many factors, hence why we need to define the correct function in each case. Parameters ---------- analogue_digital_range : float The range of analogue voltage values. scaling_factor : float A scaling factor calculated elsewhere that scales the heightmap appropriately based on the type of channel and sensor parameters. resolution : int The vertical resolution of the instrument. Dependant on the number of bits used to store its values. Typically 12, hence 2^12 = 4096 sensitivity levels. \"\"\" def __init__ ( self : Self , analogue_digital_range : float , scaling_factor : float , resolution : int ) -> None : \"\"\" Convert arbitrary height levels from the AFM into real world nanometre heights. Parameters ---------- analogue_digital_range : float The range of analogue voltage values. scaling_factor : float A scaling factor calculated elsewhere that scales the heightmap appropriately based on the type of channel and sensor parameters. resolution : int The vertical resolution of the instrumen. Dependant on the number of bits used to store its values. Typically 12, hence 2^12 = 4096 sensitivity levels. \"\"\" self . ad_range = analogue_digital_range self . scaling_factor = scaling_factor self . resolution = resolution logger . info ( f \"created voltage converter. ad_range: { analogue_digital_range } -> { self . ad_range } , \" f \" scaling factor: { scaling_factor } , resolution: { resolution } \" )","title":"VoltageLevelConverter"},{"location":"api/asd/#AFMReader.asd.VoltageLevelConverter.__init__","text":"Convert arbitrary height levels from the AFM into real world nanometre heights. Parameters: Name Type Description Default analogue_digital_range float The range of analogue voltage values. required scaling_factor float A scaling factor calculated elsewhere that scales the heightmap appropriately based on the type of channel and sensor parameters. required resolution int The vertical resolution of the instrumen. Dependant on the number of bits used to store its values. Typically 12, hence 2^12 = 4096 sensitivity levels. required Source code in AFMReader/asd.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def __init__ ( self : Self , analogue_digital_range : float , scaling_factor : float , resolution : int ) -> None : \"\"\" Convert arbitrary height levels from the AFM into real world nanometre heights. Parameters ---------- analogue_digital_range : float The range of analogue voltage values. scaling_factor : float A scaling factor calculated elsewhere that scales the heightmap appropriately based on the type of channel and sensor parameters. resolution : int The vertical resolution of the instrumen. Dependant on the number of bits used to store its values. Typically 12, hence 2^12 = 4096 sensitivity levels. \"\"\" self . ad_range = analogue_digital_range self . scaling_factor = scaling_factor self . resolution = resolution logger . info ( f \"created voltage converter. ad_range: { analogue_digital_range } -> { self . ad_range } , \" f \" scaling factor: { scaling_factor } , resolution: { resolution } \" )","title":"__init__"},{"location":"api/asd/#AFMReader.asd.calculate_scaling_factor","text":"Calculate the correct scaling factor. This function should be used in conjunction with the VoltageLevelConverter class to define the correct function and enables conversion between arbitrary level values from the AFM into real world nanometre height values. Parameters: Name Type Description Default channel str The .asd channel being used. required z_piezo_gain float The z_piezo_gain listed in the header metadata for the .asd file. required z_piezo_extension float The z_piezo_extension listed in the header metadata for the .asd file. required scanner_sensitivity float The scanner_sensitivity listed in the header metadata for the .asd file. required phase_sensitivity float The phase_sensitivity listed in the heder metadata for the .asd file. required Returns: Type Description float The appropriate scaling factor to pass to a VoltageLevelConverter to convert arbitrary height levels to real world nanometre heights for the frame data in the specified channl in the .asd file. Source code in AFMReader/asd.py 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def calculate_scaling_factor ( channel : str , z_piezo_gain : float , z_piezo_extension : float , scanner_sensitivity : float , phase_sensitivity : float , ) -> float : \"\"\" Calculate the correct scaling factor. This function should be used in conjunction with the VoltageLevelConverter class to define the correct function and enables conversion between arbitrary level values from the AFM into real world nanometre height values. Parameters ---------- channel : str The .asd channel being used. z_piezo_gain : float The z_piezo_gain listed in the header metadata for the .asd file. z_piezo_extension : float The z_piezo_extension listed in the header metadata for the .asd file. scanner_sensitivity : float The scanner_sensitivity listed in the header metadata for the .asd file. phase_sensitivity : float The phase_sensitivity listed in the heder metadata for the .asd file. Returns ------- float The appropriate scaling factor to pass to a VoltageLevelConverter to convert arbitrary height levels to real world nanometre heights for the frame data in the specified channl in the .asd file. \"\"\" if channel == \"TP\" : logger . info ( f \"Scaling factor: Type: { channel } -> TP | piezo extension { z_piezo_gain } \" f \"* piezo gain { z_piezo_extension } = scaling factor { z_piezo_gain * z_piezo_extension } \" ) return z_piezo_gain * z_piezo_extension if channel == \"ER\" : logger . info ( f \"Scaling factor: Type: { channel } -> ER | - scanner sensitivity { - scanner_sensitivity } \" f \"= scaling factor { - scanner_sensitivity } \" ) return - scanner_sensitivity if channel == \"PH\" : logger . info ( f \"Scaling factor: Type: { channel } -> PH | - phase sensitivity { - phase_sensitivity } \" f \"= scaling factor { - phase_sensitivity } \" ) return - phase_sensitivity raise ValueError ( f \"channel { channel } not known for .asd file type.\" )","title":"calculate_scaling_factor"},{"location":"api/asd/#AFMReader.asd.create_analogue_digital_converter","text":"Create an analogue to digital converter for a given range, scaling factor and resolution. Used for converting raw level values into real world height scales in nanometres. Parameters: Name Type Description Default analogue_digital_range float The range of analogue voltage values. required scaling_factor float A scaling factor calculated elsewhere that scales the heightmap appropriately based on the type of channel and sensor parameters. required resolution int The vertical resolution of the instrumen. Dependant on the number of bits used to store its values. Typically 12, hence 2^12 = 4096 sensitivity levels. 4096 Returns: Type Description VoltageLevelConverter An instance of the VoltageLevelConverter class with a tailored function level_to_voltage which converts arbitrary level values into real world nanometre heights for the given .asd file. Note that this is file specific since the parameters will change between files. Source code in AFMReader/asd.py 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 def create_analogue_digital_converter ( analogue_digital_range : float , scaling_factor : float , resolution : int = 4096 ) -> VoltageLevelConverter : \"\"\" Create an analogue to digital converter for a given range, scaling factor and resolution. Used for converting raw level values into real world height scales in nanometres. Parameters ---------- analogue_digital_range : float The range of analogue voltage values. scaling_factor : float A scaling factor calculated elsewhere that scales the heightmap appropriately based on the type of channel and sensor parameters. resolution : int The vertical resolution of the instrumen. Dependant on the number of bits used to store its values. Typically 12, hence 2^12 = 4096 sensitivity levels. Returns ------- VoltageLevelConverter An instance of the VoltageLevelConverter class with a tailored function `level_to_voltage` which converts arbitrary level values into real world nanometre heights for the given .asd file. Note that this is file specific since the parameters will change between files. \"\"\" # Analogue to digital hex conversion range encoding: # unipolar_1_00V : 0x00000001 +0.00 to +1.00 V # unipolar_2_50V : 0x00000002 +0.00 to +2.50 V # unipolar_9.99v : 0x00000003 +0.00 to +9.99 V # unipolar_5_00V : 0x00000004 +0.00 to +5.00 V # bipolar_1_00V : 0x00010000 -1.00 to +1.00 V # bipolar_2_50V : 0x00020000 -2.50 to +2.50 V # bipolar_5_00V : 0x00040000 -5.00 to +5.00 V converter : VoltageLevelConverter if analogue_digital_range == hex ( 0x00000001 ): # unipolar 1.0V mapping = ( 0.0 , 1.0 ) converter = UnipolarConverter ( analogue_digital_range = 1.0 , resolution = resolution , scaling_factor = scaling_factor , ) elif analogue_digital_range == hex ( 0x00000002 ): # unipolar 2.5V mapping = ( 0.0 , 2.5 ) converter = UnipolarConverter ( analogue_digital_range = 2.5 , resolution = resolution , scaling_factor = scaling_factor , ) elif analogue_digital_range == hex ( 0x00000003 ): mapping = ( 0 , 9.99 ) converter = UnipolarConverter ( analogue_digital_range = 9.99 , resolution = resolution , scaling_factor = scaling_factor , ) elif analogue_digital_range == hex ( 0x00000004 ): # unipolar 5.0V mapping = ( 0.0 , 5.0 ) converter = UnipolarConverter ( analogue_digital_range = 5.0 , resolution = resolution , scaling_factor = scaling_factor , ) elif analogue_digital_range == hex ( 0x00010000 ): # bipolar 1.0V mapping = ( - 1.0 , 1.0 ) converter = BipolarConverter ( analogue_digital_range = 1.0 , resolution = resolution , scaling_factor = scaling_factor , ) elif analogue_digital_range == hex ( 0x00020000 ): # bipolar 2.5V mapping = ( - 2.5 , 2.5 ) converter = BipolarConverter ( analogue_digital_range = 2.5 , resolution = resolution , scaling_factor = scaling_factor , ) elif analogue_digital_range == hex ( 0x00040000 ): # bipolar 5.0V mapping = ( - 5.0 , 5.0 ) converter = BipolarConverter ( analogue_digital_range = 5.0 , resolution = resolution , scaling_factor = scaling_factor , ) else : raise ValueError ( f \"Analogue to digital range hex value { analogue_digital_range } has no known \" \"analogue-digital mapping.\" ) logger . info ( f \"Analogue to digital mapping | Range: { analogue_digital_range } -> { mapping } \" ) logger . info ( f \"Converter: { converter } \" ) return converter","title":"create_analogue_digital_converter"},{"location":"api/asd/#AFMReader.asd.create_animation","text":"Create animation from a numpy array of frames (2d numpy arrays). File format can be specified, defaults to .gif. Parameters: Name Type Description Default file_name str Name of the file to save. required frames NDArray Numpy array of frames of shape (N x W x H) where N is the number of frames, W is the width of the frames and H is the height of the frames. required file_format str Optional string for the file format to save as. Formats currently available: .mp4, .gif. '.gif' Source code in AFMReader/asd.py 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 def create_animation ( file_name : str , frames : npt . NDArray , file_format : str = \".gif\" ) -> None : \"\"\" Create animation from a numpy array of frames (2d numpy arrays). File format can be specified, defaults to .gif. Parameters ---------- file_name : str Name of the file to save. frames : npt.NDArray Numpy array of frames of shape (N x W x H) where N is the number of frames, W is the width of the frames and H is the height of the frames. file_format : str Optional string for the file format to save as. Formats currently available: .mp4, .gif. \"\"\" fig , axis = plt . subplots () def update ( frame : npt . NDArray ): \"\"\" Update the image with the latest frame. Parameters ---------- frame : npt.NDArray Single frame to add to the image. Returns ------- axis Matplotlib axis. \"\"\" axis . imshow ( frames [ frame ]) return axis # Create the animation object ani = animation . FuncAnimation ( fig , update , frames = frames . shape [ 0 ], interval = 200 ) if file_format == \".mp4\" : ani . save ( f \" { file_name } .mp4\" , writer = \"ffmpeg\" ) elif file_format == \".gif\" : ani . save ( f \" { file_name } .gif\" , writer = \"imagemagick\" ) else : raise ValueError ( f \" { file_format } format not supported yet.\" )","title":"create_animation"},{"location":"api/asd/#AFMReader.asd.load_asd","text":"Load a .asd file. Parameters: Name Type Description Default file_path Path Path to the .asd file. required channel str Channel to load. Note that only three channels seem to be present in a single .asd file. Options: TP (Topograph), ER (Error) and PH (Phase). required Returns: Type Description NDArray The .asd file frames data as a numpy 3D array N x W x H (Number of frames x Width of each frame x height of each frame). float The number of nanometres per pixel for the .asd file. (AKA the resolution). Enables converting between pixels and nanometres when working with the data, in order to use real-world length scales. dict Metadata for the .asd file. The number of entries is too long to list here, and changes based on the file version please either look into the read_header_file_version_x functions or print the keys too see what metadata is available. Source code in AFMReader/asd.py 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 def load_asd ( file_path : str | Path , channel : str ): \"\"\" Load a .asd file. Parameters ---------- file_path : Path Path to the .asd file. channel : str Channel to load. Note that only three channels seem to be present in a single .asd file. Options: TP (Topograph), ER (Error) and PH (Phase). Returns ------- npt.NDArray The .asd file frames data as a numpy 3D array N x W x H (Number of frames x Width of each frame x height of each frame). float The number of nanometres per pixel for the .asd file. (AKA the resolution). Enables converting between pixels and nanometres when working with the data, in order to use real-world length scales. dict Metadata for the .asd file. The number of entries is too long to list here, and changes based on the file version please either look into the `read_header_file_version_x` functions or print the keys too see what metadata is available. \"\"\" # Ensure the file path is a Path object file_path = Path ( file_path ) filename = file_path . stem # Check the file exists and raise an error if not if not file_path . is_file (): logger . error ( f \"[ { filename } ] File not found : { file_path } \" ) raise FileNotFoundError ( errno . ENOENT , os . strerror ( errno . ENOENT ), file_path ) # Open the file in binary mode with Path . open ( file_path , \"rb\" , encoding = None ) as open_file : # pylint: disable=unspecified-encoding file_version = read_file_version ( open_file ) if file_version == 0 : header_dict = read_header_file_version_0 ( open_file ) elif file_version == 1 : header_dict = read_header_file_version_1 ( open_file ) elif file_version == 2 : header_dict = read_header_file_version_2 ( open_file ) else : raise ValueError ( f \"File version { file_version } unknown. Please add support if you \" \"know how to decode this file version.\" ) logger . debug ( f \"header dict: \\n { header_dict } \" ) pixel_to_nanometre_scaling_factor_x = header_dict [ \"x_nm\" ] / header_dict [ \"x_pixels\" ] pixel_to_nanometre_scaling_factor_y = header_dict [ \"y_nm\" ] / header_dict [ \"y_pixels\" ] if pixel_to_nanometre_scaling_factor_x != pixel_to_nanometre_scaling_factor_y : logger . warning ( f \"Resolution of image is different in x and y directions:\" f \"x: { pixel_to_nanometre_scaling_factor_x } \" f \"y: { pixel_to_nanometre_scaling_factor_y } \" ) pixel_to_nanometre_scaling_factor = pixel_to_nanometre_scaling_factor_x if channel == header_dict [ \"channel1\" ]: logger . info ( f \"Requested channel { channel } matches first channel in file: { header_dict [ 'channel1' ] } \" ) elif channel == header_dict [ \"channel2\" ]: logger . info ( f \"Requested channel { channel } matches second channel in file: \" f \" { header_dict [ 'channel2' ] } \" ) # Skip first channel data _size_of_frame_header = header_dict [ \"frame_header_length\" ] # Remember that each value is two bytes (since signed int16) size_of_single_frame_plus_header = ( header_dict [ \"frame_header_length\" ] + header_dict [ \"x_pixels\" ] * header_dict [ \"y_pixels\" ] * 2 ) length_of_all_first_channel_frames = header_dict [ \"num_frames\" ] * size_of_single_frame_plus_header _ = open_file . read ( length_of_all_first_channel_frames ) else : raise ValueError ( f \"Channel { channel } not found in this file's available channels: \" f \" { header_dict [ 'channel1' ] } , { header_dict [ 'channel2' ] } \" ) scaling_factor = calculate_scaling_factor ( channel = channel , z_piezo_gain = header_dict [ \"z_piezo_gain\" ], z_piezo_extension = header_dict [ \"z_piezo_extension\" ], scanner_sensitivity = header_dict [ \"scanner_sensitivity\" ], phase_sensitivity = header_dict [ \"phase_sensitivity\" ], ) analogue_digital_converter = create_analogue_digital_converter ( analogue_digital_range = header_dict [ \"analogue_digital_range\" ], scaling_factor = scaling_factor , ) frames = read_channel_data ( open_file = open_file , num_frames = header_dict [ \"num_frames\" ], x_pixels = header_dict [ \"x_pixels\" ], y_pixels = header_dict [ \"y_pixels\" ], analogue_digital_converter = analogue_digital_converter , ) frames = np . array ( frames ) return frames , pixel_to_nanometre_scaling_factor , header_dict","title":"load_asd"},{"location":"api/asd/#AFMReader.asd.read_channel_data","text":"Read frame data from an open .asd file, starting at the current position. Parameters: Name Type Description Default open_file BinaryIO An open binary file object for a .asd file. required num_frames int The number of frames for this set of frame data. required x_pixels int The width of each frame in pixels. required y_pixels int The height of each frame in pixels. required analogue_digital_converter VoltageLevelConverter A VoltageLevelConverter instance for converting the raw level values to real world nanometre vertical heights. required Returns: Type Description ndarray The extracted frame heightmap data as a N x W x H 3D numpy array (number of frames x width of each frame x height of each frame). Units are nanometres. Source code in AFMReader/asd.py 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 def read_channel_data ( open_file : BinaryIO , num_frames : int , x_pixels : int , y_pixels : int , analogue_digital_converter : VoltageLevelConverter , ) -> npt . NDArray : \"\"\" Read frame data from an open .asd file, starting at the current position. Parameters ---------- open_file : BinaryIO An open binary file object for a .asd file. num_frames : int The number of frames for this set of frame data. x_pixels : int The width of each frame in pixels. y_pixels : int The height of each frame in pixels. analogue_digital_converter : VoltageLevelConverter A VoltageLevelConverter instance for converting the raw level values to real world nanometre vertical heights. Returns ------- np.ndarray The extracted frame heightmap data as a N x W x H 3D numpy array (number of frames x width of each frame x height of each frame). Units are nanometres. \"\"\" # List to store the frames as numpy arrays frames = [] # Dictionary to store all the variables together in case we want to return them. # Very useful for debugging! frame_header_dict = {} for _ in range ( num_frames ): frame_header_dict [ \"frame_number\" ] = read_int32 ( open_file ) frame_header_dict [ \"max_data\" ] = read_int16 ( open_file ) frame_header_dict [ \"min_data\" ] = read_int16 ( open_file ) frame_header_dict [ \"x_offset\" ] = read_int16 ( open_file ) frame_header_dict [ \"y_offset\" ] = read_int16 ( open_file ) frame_header_dict [ \"x_tilt\" ] = read_float ( open_file ) frame_header_dict [ \"y_tilt\" ] = read_float ( open_file ) frame_header_dict [ \"is_stimulated\" ] = read_bool ( open_file ) _booked_1 = read_int8 ( open_file ) _booked_2 = read_int16 ( open_file ) _booked_3 = read_int32 ( open_file ) _booked_4 = read_int32 ( open_file ) frame_header_dict [ \"total_size\" ] = x_pixels * y_pixels # Read frame byte data. Data is always stored as signed 2 byte integer form # so multiply the size of the array by 2 frame_header_dict [ \"total_byte_size\" ] = frame_header_dict [ \"total_size\" ] * 2 frame_data = open_file . read ( frame_header_dict [ \"total_size\" ] * 2 ) # Decode frame data from bytes. Data is always stored in signed 2 byte integer form frame_data = np . frombuffer ( frame_data , dtype = np . int16 ) # Convert from Voltage to Real units frame_data = analogue_digital_converter . level_to_voltage ( frame_data ) # type: ignore # Reshape frame to 2D array frame_data = frame_data . reshape (( y_pixels , x_pixels )) # type: ignore frames . append ( frame_data ) return frames","title":"read_channel_data"},{"location":"api/asd/#AFMReader.asd.read_file_version","text":"Read the file version from an open asd file. File versions are 0, 1 and 2. Different file versions require different functions to read the headers as the formatting changes between them. Parameters: Name Type Description Default open_file BinaryIO An open binary file object for a .asd file. required Returns: Type Description int Integer file version decoded from file. Source code in AFMReader/asd.py 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 def read_file_version ( open_file : BinaryIO ) -> int : \"\"\" Read the file version from an open asd file. File versions are 0, 1 and 2. Different file versions require different functions to read the headers as the formatting changes between them. Parameters ---------- open_file : BinaryIO An open binary file object for a .asd file. Returns ------- int Integer file version decoded from file. \"\"\" file_version = read_int32 ( open_file ) logger . info ( f \"file version: { file_version } \" ) return file_version","title":"read_file_version"},{"location":"api/asd/#AFMReader.asd.read_header_file_version_0","text":"Read the header metadata for a .asd file using file version 0. Parameters: Name Type Description Default open_file BinaryIO An open binary file object for a .asd file. required Returns: Type Description dict Dictionary of metadata decoded from the file header. Source code in AFMReader/asd.py 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 def read_header_file_version_0 ( open_file : BinaryIO ) -> dict : \"\"\" Read the header metadata for a .asd file using file version 0. Parameters ---------- open_file : BinaryIO An open binary file object for a .asd file. Returns ------- dict Dictionary of metadata decoded from the file header. \"\"\" header_dict : dict [ str , Any ] = {} # There only ever seem to be two channels available # Channel encoding are all in LITTLE ENDIAN format. # topology: 0x5054 decodes to 'TP' in ascii little endian # error: 0x5245 decodes to 'ER' in ascii little endian # phase: 0x4850 decodes to 'PH' in ascii little endian header_dict [ \"channel1\" ] = read_ascii ( open_file , 2 ) header_dict [ \"channel2\" ] = read_ascii ( open_file , 2 ) # length of file metadata header in bytes - so we can skip it to get to the data header_dict [ \"header_length\" ] = read_int32 ( open_file ) # Frame header is the length of the header for each frame to be skipped # before reading frame data. header_dict [ \"frame_header_length\" ] = read_int32 ( open_file ) # Length in bytes of the name given in the file header_dict [ \"user_name_size\" ] = read_int32 ( open_file ) header_dict [ \"comment_offset_size\" ] = read_int32 ( open_file ) # Length in bytes of the comment for the file header_dict [ \"comment_size\" ] = read_int32 ( open_file ) # x and y resolution (pixels) header_dict [ \"x_pixels\" ] = read_int16 ( open_file ) header_dict [ \"y_pixels\" ] = read_int16 ( open_file ) # x and y resolution (nm) header_dict [ \"x_nm\" ] = read_int16 ( open_file ) header_dict [ \"y_nm\" ] = read_int16 ( open_file ) # frame time header_dict [ \"frame_time\" ] = read_float ( open_file ) # z piezo extension header_dict [ \"z_piezo_extension\" ] = read_float ( open_file ) # z piezo gain header_dict [ \"z_piezo_gain\" ] = read_float ( open_file ) # Range of analogue voltage values (for conversion to digital) header_dict [ \"analogue_digital_range\" ] = read_hex_u32 ( open_file ) # Number of bits of data for analogue voltage values (for conversion to digital) # aka the resolution of the instrument. Usually 12 bits, so 4096 sensitivity levels header_dict [ \"analogue_digital_data_bits_size\" ] = read_int32 ( open_file ) header_dict [ \"analogue_digital_resolution\" ] = 2 ^ header_dict [ \"analogue_digital_data_bits_size\" ] # Not sure, something to do with data averaging header_dict [ \"is_averaged\" ] = read_bool ( open_file ) # Window for averaging the data header_dict [ \"averaging_window\" ] = read_int32 ( open_file ) # Some padding to ensure backwards compatilibilty I think _ = read_int16 ( open_file ) # Date of creation header_dict [ \"year\" ] = read_int16 ( open_file ) header_dict [ \"month\" ] = read_uint8 ( open_file ) header_dict [ \"day\" ] = read_uint8 ( open_file ) header_dict [ \"hour\" ] = read_uint8 ( open_file ) header_dict [ \"minute\" ] = read_uint8 ( open_file ) header_dict [ \"second\" ] = read_uint8 ( open_file ) # Rounding degree? header_dict [ \"rounding_degree\" ] = read_uint8 ( open_file ) # Maximum x and y scanning range in real space, nm header_dict [ \"max_x_scan_range\" ] = read_float ( open_file ) header_dict [ \"max_y_scan_range\" ] = read_float ( open_file ) # No idea _ = read_int32 ( open_file ) _ = read_int32 ( open_file ) _ = read_int32 ( open_file ) # Number of frames the file had when recorded header_dict [ \"initial_frames\" ] = read_int32 ( open_file ) # Actual number of frames header_dict [ \"num_frames\" ] = read_int32 ( open_file ) # ID of the AFM instrument header_dict [ \"afm_id\" ] = read_int32 ( open_file ) # ID of the file header_dict [ \"file_id\" ] = read_int16 ( open_file ) # Name of the user header_dict [ \"user_name\" ] = read_null_separated_utf8 ( open_file , length_bytes = header_dict [ \"user_name_size\" ]) # Sensitivity of the scanner in nm / V header_dict [ \"scanner_sensitivity\" ] = read_float ( open_file ) # Phase sensitivity header_dict [ \"phase_sensitivity\" ] = read_float ( open_file ) # Direction of the scan header_dict [ \"scan_direction\" ] = read_int32 ( open_file ) # Skip bytes: comment offset size _ = skip_bytes ( open_file , header_dict [ \"comment_offset_size\" ]) # Read a comment comment = [] for _ in range ( header_dict [ \"comment_size\" ]): comment . append ( chr ( read_int8 ( open_file ))) header_dict [ \"comment_without_null\" ] = \"\" . join ([ c for c in comment if c != \" \\x00 \" ]) return header_dict","title":"read_header_file_version_0"},{"location":"api/asd/#AFMReader.asd.read_header_file_version_1","text":"Read the header metadata for a .asd file using file version 1. Parameters: Name Type Description Default open_file BinaryIO An open binary file object for a .asd file. required Returns: Type Description dict Dictionary of metadata decoded from the file header. Source code in AFMReader/asd.py 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 def read_header_file_version_1 ( open_file : BinaryIO ) -> dict [ str , int ]: \"\"\" Read the header metadata for a .asd file using file version 1. Parameters ---------- open_file : BinaryIO An open binary file object for a .asd file. Returns ------- dict Dictionary of metadata decoded from the file header. \"\"\" header_dict = {} # length of file metadata header in bytes - so we can skip it to get to the data header_dict [ \"header_length\" ] = read_int32 ( open_file ) # Frame header is the length of the header for each frame to be skipped before # reading frame data. header_dict [ \"frame_header_length\" ] = read_int32 ( open_file ) # Encoding for strings header_dict [ \"text_encoding\" ] = read_int32 ( open_file ) # Length in bytes of the name given in the file header_dict [ \"user_name_size\" ] = read_int32 ( open_file ) # Length in bytes of the comment for the file header_dict [ \"comment_size\" ] = read_int32 ( open_file ) # There only ever seem to be two channels available # Channel encoding are all in LITTLE ENDIAN format. # topology: 0x5054 decodes to 'TP' in ascii little endian # error: 0x5245 decodes to 'ER' in ascii little endian # phase: 0x4850 decodes to 'PH' in ascii little endian header_dict [ \"channel1\" ] = read_null_separated_utf8 ( open_file , length_bytes = 4 ) header_dict [ \"channel2\" ] = read_null_separated_utf8 ( open_file , length_bytes = 4 ) # Number of frames the file had when recorded header_dict [ \"initial_frames\" ] = read_int32 ( open_file ) # Actual number of frames header_dict [ \"num_frames\" ] = read_int32 ( open_file ) # Direction of the scan header_dict [ \"scan_direction\" ] = read_int32 ( open_file ) # ID of the file header_dict [ \"file_id\" ] = read_int32 ( open_file ) # x and y resolution (pixels) header_dict [ \"x_pixels\" ] = read_int32 ( open_file ) header_dict [ \"y_pixels\" ] = read_int32 ( open_file ) # x and y resolution (nm) header_dict [ \"x_nm\" ] = read_int32 ( open_file ) header_dict [ \"y_nm\" ] = read_int32 ( open_file ) # Not sure, something to do with data averaging header_dict [ \"is_averaged\" ] = read_bool ( open_file ) # Window for averaging the data header_dict [ \"averaging_window\" ] = read_int32 ( open_file ) # Date of creation header_dict [ \"year\" ] = read_int32 ( open_file ) header_dict [ \"month\" ] = read_int32 ( open_file ) header_dict [ \"day\" ] = read_int32 ( open_file ) header_dict [ \"hour\" ] = read_int32 ( open_file ) header_dict [ \"minute\" ] = read_int32 ( open_file ) header_dict [ \"second\" ] = read_int32 ( open_file ) # Rounding degree? header_dict [ \"x_rounding_degree\" ] = read_int32 ( open_file ) header_dict [ \"y_rounding_degree\" ] = read_int32 ( open_file ) # frame time header_dict [ \"frame_time\" ] = read_float ( open_file ) # Sensitivity of the scanner in nm / V header_dict [ \"scanner_sensitivity\" ] = read_float ( open_file ) # Phase sensitivity header_dict [ \"phase_sensitivity\" ] = read_float ( open_file ) # Offset? header_dict [ \"offset\" ] = read_int32 ( open_file ) # Ignore 12 bytes _ = skip_bytes ( open_file , 12 ) # ID of the AFM instrument header_dict [ \"afm_id\" ] = read_int32 ( open_file ) # Range of analogue voltage values (for conversion to digital) header_dict [ \"analogue_digital_range\" ] = read_hex_u32 ( open_file ) # Number of bits of data for analogue voltage values (for conversion to digital) # aka the resolution of the instrument. Usually 12 bits, so 4096 sensitivity levels header_dict [ \"analogue_digital_data_bits_size\" ] = read_int32 ( open_file ) header_dict [ \"analogue_digital_resolution\" ] = 2 ^ header_dict [ \"analogue_digital_data_bits_size\" ] # Maximum x and y scanning range in real space, nm header_dict [ \"max_x_scan_range\" ] = read_float ( open_file ) header_dict [ \"max_y_scan_range\" ] = read_float ( open_file ) # Piezo extensions header_dict [ \"x_piezo_extension\" ] = read_float ( open_file ) header_dict [ \"y_piezo_extension\" ] = read_float ( open_file ) header_dict [ \"z_piezo_extension\" ] = read_float ( open_file ) # Piezo gain header_dict [ \"z_piezo_gain\" ] = read_float ( open_file ) # Read the user name user_name = [] for _ in range ( header_dict [ \"user_name_size\" ]): user_name . append ( chr ( read_int8 ( open_file ))) header_dict [ \"user_name\" ] = \"\" . join ([ c for c in user_name if c != \" \\x00 \" ]) # Read a comment comment = [] for _ in range ( header_dict [ \"comment_size\" ]): comment . append ( chr ( read_int8 ( open_file ))) header_dict [ \"comment_without_null\" ] = \"\" . join ([ c for c in comment if c != \" \\x00 \" ]) return header_dict","title":"read_header_file_version_1"},{"location":"api/asd/#AFMReader.asd.read_header_file_version_2","text":"Read the header metadata for a .asd file using file version 2. Parameters: Name Type Description Default open_file BinaryIO An open binary file object for a .asd file. required Returns: Type Description dict Dictionary of metadata decoded from the file header. Source code in AFMReader/asd.py 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 def read_header_file_version_2 ( open_file : BinaryIO ) -> dict : \"\"\" Read the header metadata for a .asd file using file version 2. Parameters ---------- open_file : BinaryIO An open binary file object for a .asd file. Returns ------- dict Dictionary of metadata decoded from the file header. \"\"\" header_dict = {} # length of file metadata header in bytes - so we can skip it to get to the data header_dict [ \"header_length\" ] = read_int32 ( open_file ) # Frame header is the length of the header for each frame to be skipped before # reading frame data. header_dict [ \"frame_header_length\" ] = read_int32 ( open_file ) # Encoding for strings header_dict [ \"text_encoding\" ] = read_int32 ( open_file ) # Length in bytes of the name given in the file header_dict [ \"user_name_size\" ] = read_int32 ( open_file ) # Length in bytes of the comment for the file header_dict [ \"comment_size\" ] = read_int32 ( open_file ) # There only ever seem to be two channels available # Channel encoding are all in LITTLE ENDIAN format. # topology: 0x5054 decodes to 'TP' in ascii little endian # error: 0x5245 decodes to 'ER' in ascii little endian # phase: 0x4850 decodes to 'PH' in ascii little endian header_dict [ \"channel1\" ] = read_null_separated_utf8 ( open_file , length_bytes = 4 ) header_dict [ \"channel2\" ] = read_null_separated_utf8 ( open_file , length_bytes = 4 ) # Number of frames the file had when recorded header_dict [ \"initial_frames\" ] = read_int32 ( open_file ) # Actual number of frames header_dict [ \"num_frames\" ] = read_int32 ( open_file ) # Direction of the scan header_dict [ \"scan_direction\" ] = read_int32 ( open_file ) # ID of the file header_dict [ \"file_id\" ] = read_int32 ( open_file ) # x and y resolution (pixels) header_dict [ \"x_pixels\" ] = read_int32 ( open_file ) header_dict [ \"y_pixels\" ] = read_int32 ( open_file ) # x and y resolution (nm) header_dict [ \"x_nm\" ] = read_int32 ( open_file ) header_dict [ \"y_nm\" ] = read_int32 ( open_file ) # Not sure, something to do with data averaging header_dict [ \"is_averaged\" ] = read_bool ( open_file ) # Window for averaging the data header_dict [ \"averaging_window\" ] = read_int32 ( open_file ) # Date of creation header_dict [ \"year\" ] = read_int32 ( open_file ) header_dict [ \"month\" ] = read_int32 ( open_file ) header_dict [ \"day\" ] = read_int32 ( open_file ) header_dict [ \"hour\" ] = read_int32 ( open_file ) header_dict [ \"minute\" ] = read_int32 ( open_file ) header_dict [ \"second\" ] = read_int32 ( open_file ) # Rounding degree? header_dict [ \"x_rounding_degree\" ] = read_int32 ( open_file ) header_dict [ \"y_rounding_degree\" ] = read_int32 ( open_file ) # frame time header_dict [ \"frame_time\" ] = read_float ( open_file ) # Sensitivity of the scanner in nm / V header_dict [ \"scanner_sensitivity\" ] = read_float ( open_file ) # Phase sensitivity header_dict [ \"phase_sensitivity\" ] = read_float ( open_file ) # Offset? header_dict [ \"offset\" ] = read_int32 ( open_file ) # Ignore 12 bytes _ = skip_bytes ( open_file , 12 ) # ID of the AFM instrument header_dict [ \"afm_id\" ] = read_int32 ( open_file ) # Range of analogue voltage values (for conversion to digital) header_dict [ \"analogue_digital_range\" ] = read_hex_u32 ( open_file ) # Number of bits of data for analogue voltage values (for conversion to digital) # aka the resolution of the instrument. Usually 12 bits, so 4096 sensitivity levels header_dict [ \"analogue_digital_data_bits_size\" ] = read_int32 ( open_file ) header_dict [ \"analogue_digital_resolution\" ] = 2 ^ header_dict [ \"analogue_digital_data_bits_size\" ] # Maximum x and y scanning range in real space, nm header_dict [ \"max_x_scan_range\" ] = read_float ( open_file ) header_dict [ \"max_y_scan_range\" ] = read_float ( open_file ) # Piezo extensions header_dict [ \"x_piezo_extension\" ] = read_float ( open_file ) header_dict [ \"y_piezo_extension\" ] = read_float ( open_file ) header_dict [ \"z_piezo_extension\" ] = read_float ( open_file ) # Piezo gain header_dict [ \"z_piezo_gain\" ] = read_float ( open_file ) # Read the user name user_name = [] for _ in range ( header_dict [ \"user_name_size\" ]): user_name . append ( chr ( read_int8 ( open_file ))) header_dict [ \"user_name\" ] = \"\" . join ([ c for c in user_name if c != \" \\x00 \" ]) # Read a comment comment = [] for _ in range ( header_dict [ \"comment_size\" ]): comment . append ( chr ( read_int8 ( open_file ))) header_dict [ \"comment_without_null\" ] = \"\" . join ([ c for c in comment if c != \" \\x00 \" ]) # No idea why this file type has the number of frames again. Storing it just in case. header_dict [ \"number_of_frames\" ] = read_int32 ( open_file ) # Feed forward parameter, no idea what it does. header_dict [ \"is_x_feed_forward_integer\" ] = read_int32 ( open_file ) # Feed forward parameter, no idea what it does. header_dict [ \"is_x_feed_forward_double\" ] = read_double ( open_file ) # Minimum and maximum colour mapping values header_dict [ \"max_colour_scale\" ] = read_int32 ( open_file ) header_dict [ \"min_colour_scale\" ] = read_int32 ( open_file ) # RGB anchor point array sizes header_dict [ \"length_red_anchor_points\" ] = read_int32 ( open_file ) header_dict [ \"length_green_anchor_points\" ] = read_int32 ( open_file ) header_dict [ \"length_blue_anchor_points\" ] = read_int32 ( open_file ) # Coords of anchor points # Red coords_red = [] for _ in range ( header_dict [ \"length_red_anchor_points\" ]): anchor_x = read_int32 ( open_file ) anchor_y = read_int32 ( open_file ) coords_red . append (( anchor_x , anchor_y )) # Green coords_green = [] for _ in range ( header_dict [ \"length_green_anchor_points\" ]): anchor_x = read_int32 ( open_file ) anchor_y = read_int32 ( open_file ) coords_green . append (( anchor_x , anchor_y )) # Blue coords_blue = [] for _ in range ( header_dict [ \"length_blue_anchor_points\" ]): anchor_x = read_int32 ( open_file ) anchor_y = read_int32 ( open_file ) coords_blue . append (( anchor_x , anchor_y )) return header_dict","title":"read_header_file_version_2"},{"location":"api/gwy/","text":"GWY Modules For decoding and loading .gwy AFM file format into Python Numpy arrays. gwy_get_channels ( gwy_file_structure ) Extract a list of channels and their corresponding dictionary key ids from the .gwy file dictionary. Parameters: Name Type Description Default gwy_file_structure dict Dictionary of the nested object / component structure of a .gwy file. Where the keys are object names and the values are dictionaries of the object's components. required Returns: Type Description dict Dictionary where the keys are the channel names and the values are the dictionary key ids. Examples: Using a loaded dictionary generated from a .gwy file: LoadScans._gwy_get_channels(gwy_file_structure=loaded_gwy_file_dictionary) Source code in AFMReader/gwy.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 def gwy_get_channels ( gwy_file_structure : dict ) -> dict : \"\"\" Extract a list of channels and their corresponding dictionary key ids from the `.gwy` file dictionary. Parameters ---------- gwy_file_structure : dict Dictionary of the nested object / component structure of a `.gwy` file. Where the keys are object names and the values are dictionaries of the object's components. Returns ------- dict Dictionary where the keys are the channel names and the values are the dictionary key ids. Examples -------- # Using a loaded dictionary generated from a `.gwy` file: LoadScans._gwy_get_channels(gwy_file_structure=loaded_gwy_file_dictionary) \"\"\" title_key_pattern = re . compile ( r \"\\d+(?=/data/title)\" ) channel_ids = {} for key , _ in gwy_file_structure . items (): match = re . search ( title_key_pattern , key ) if match : channel = gwy_file_structure [ key ] channel_ids [ channel ] = match . group () return channel_ids gwy_read_component ( open_file , initial_byte_pos , data_dict ) Parse and extract data from a .gwy file object, starting at the current open file read position. Parameters: Name Type Description Default open_file BinaryIO An open file object. required initial_byte_pos int Initial position, as byte. required data_dict dict Dictionary of .gwy file image properties. required Returns: Type Description int Size of the component in bytes. Source code in AFMReader/gwy.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def gwy_read_component ( open_file : BinaryIO , initial_byte_pos : int , data_dict : dict ) -> int : \"\"\" Parse and extract data from a `.gwy` file object, starting at the current open file read position. Parameters ---------- open_file : BinaryIO An open file object. initial_byte_pos : int Initial position, as byte. data_dict : dict Dictionary of `.gwy` file image properties. Returns ------- int Size of the component in bytes. \"\"\" component_name = read_null_terminated_string ( open_file = open_file ) data_type = read_gwy_component_dtype ( open_file = open_file ) if data_type == \"o\" : logger . debug ( f \"component name: { component_name } | dtype: { data_type } |\" ) sub_dict : dict [ Any , Any ] = {} gwy_read_object ( open_file = open_file , data_dict = sub_dict ) data_dict [ component_name ] = sub_dict elif data_type == \"c\" : value = read_char ( open_file = open_file ) logger . debug ( f \"component name: { component_name } | dtype: { data_type } | value: { value } \" ) data_dict [ component_name ] = value elif data_type == \"i\" : value = read_uint32 ( open_file = open_file ) # type: ignore logger . debug ( f \"component name: { component_name } | dtype: { data_type } | value: { value } \" ) data_dict [ component_name ] = value elif data_type == \"d\" : value = read_double ( open_file = open_file ) # type: ignore logger . debug ( f \"component name: { component_name } | dtype: { data_type } | value: { value } \" ) data_dict [ component_name ] = value elif data_type == \"s\" : value = read_null_terminated_string ( open_file = open_file ) logger . debug ( f \"component name: { component_name } | dtype: { data_type } | value: { value } \" ) data_dict [ component_name ] = value elif data_type == \"D\" : array_size = read_uint32 ( open_file = open_file ) logger . debug ( f \"component name: { component_name } | dtype: { data_type } \" ) logger . debug ( f \"array size: { array_size } \" ) data = np . zeros ( array_size ) for index in range ( array_size ): data [ index ] = read_double ( open_file = open_file ) if \"xres\" in data_dict and \"yres\" in data_dict : data = data . reshape (( data_dict [ \"xres\" ], data_dict [ \"yres\" ])) data_dict [ \"data\" ] = data return open_file . tell () - initial_byte_pos gwy_read_object ( open_file , data_dict ) Parse and extract data from a .gwy file object, starting at the current open file read position. Parameters: Name Type Description Default open_file BinaryIO An open file object. required data_dict dict Dictionary of .gwy file image properties. required Source code in AFMReader/gwy.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def gwy_read_object ( open_file : BinaryIO , data_dict : dict ) -> None : \"\"\" Parse and extract data from a `.gwy` file object, starting at the current open file read position. Parameters ---------- open_file : BinaryIO An open file object. data_dict : dict Dictionary of `.gwy` file image properties. \"\"\" object_name = read_null_terminated_string ( open_file = open_file ) data_size = read_uint32 ( open_file ) logger . debug ( f \"OBJECT | name: { object_name } | data_size: { data_size } \" ) # Read components read_data_size = 0 while read_data_size < data_size : component_data_size = gwy_read_component ( open_file = open_file , initial_byte_pos = open_file . tell (), data_dict = data_dict , ) read_data_size += component_data_size load_gwy ( file_path , channel ) Extract image and pixel to nm scaling from the .gwy file. Parameters: Name Type Description Default file_path Path or str Path to the .gwy file. required channel str Channel name to extract from the .gwy file. required Returns: Type Description tuple ( ndarray , float ) A tuple containing the image and its pixel to nanometre scaling value. Raises: Type Description FileNotFoundError If the file is not found. ValueError If the channel is not found in the .gwy file. Examples: Load the image and pixel to nanometre scaling factor, available channels are 'Height', 'ZSensor' and 'Height Sensor'. >>> from AFMReader.gwy import load_gwy >>> image , pixel_to_nm = load_gwy ( file_path = \"path/to/file.gwy\" , channel = \"Height\" ) ``` Source code in AFMReader/gwy.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def load_gwy ( file_path : Path | str , channel : str ) -> tuple [ np . ndarray [ Any , np . dtypes . Float64DType ], float ]: \"\"\" Extract image and pixel to nm scaling from the .gwy file. Parameters ---------- file_path : Path or str Path to the .gwy file. channel : str Channel name to extract from the .gwy file. Returns ------- tuple(np.ndarray, float) A tuple containing the image and its pixel to nanometre scaling value. Raises ------ FileNotFoundError If the file is not found. ValueError If the channel is not found in the .gwy file. Examples -------- Load the image and pixel to nanometre scaling factor, available channels are 'Height', 'ZSensor' and 'Height Sensor'. >>> from AFMReader.gwy import load_gwy >>> image, pixel_to_nm = load_gwy(file_path=\"path/to/file.gwy\", channel=\"Height\") ``` \"\"\" logger . info ( f \"Loading image from : { file_path } \" ) file_path = Path ( file_path ) filename = file_path . stem try : image_data_dict : dict [ Any , Any ] = {} with Path . open ( file_path , \"rb\" ) as open_file : # pylint: disable=unspecified-encoding # Read header header = open_file . read ( 4 ) logger . debug ( f \"Gwy file header: { header . decode } \" ) gwy_read_object ( open_file , data_dict = image_data_dict ) # For development - uncomment to have an indentation based nested # dictionary output showing the object - component structure and # available keys: # LoadScans._gwy_print_dict_wrapper(gwy_file_dict=image_data_dict) channel_ids = gwy_get_channels ( gwy_file_structure = image_data_dict ) if channel not in channel_ids : raise KeyError ( f \"Channel { channel } not found in { file_path . suffix } channel list: { channel_ids } \" ) # Get the image data image = image_data_dict [ f \"/ { channel_ids [ channel ] } /data\" ][ \"data\" ] units = image_data_dict [ f \"/ { channel_ids [ channel ] } /data\" ][ \"si_unit_xy\" ][ \"unitstr\" ] # currently only support equal pixel sizes in x and y px_to_nm = image_data_dict [ f \"/ { channel_ids [ channel ] } /data\" ][ \"xreal\" ] / image . shape [ 1 ] # Convert image heights to nanometresQ if units == \"m\" : image = image * 1e9 px_to_nm = px_to_nm * 1e9 else : raise ValueError ( f \"Units ' { units } ' have not been added for .gwy files. Please add \\ an SI to nanometre conversion factor for these units in _gwy_read_component in \\ io.py.\" ) except FileNotFoundError : logger . info ( f \"[ { filename } ] File not found : { file_path } \" ) raise return ( image , px_to_nm ) read_gwy_component_dtype ( open_file ) Read the data type of a .gwy file component. Possible data types are as follows: 'b': boolean 'c': character 'i': 32-bit integer 'q': 64-bit integer 'd': double 's': string 'o': .gwy format object Capitalised versions of some of these data types represent arrays of values of that data type. Arrays are stored as an unsigned 32 bit integer, describing the size of the array, followed by the unseparated array values: 'C': array of characters 'I': array of 32-bit integers 'Q': array of 64-bit integers 'D': array of doubles 'S': array of strings 'O': array of objects. Parameters: Name Type Description Default open_file BinaryIO An open file object. required Returns: Type Description str Python string (one character long) of the data type of the component's value. Source code in AFMReader/gwy.py 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 def read_gwy_component_dtype ( open_file : BinaryIO ) -> str : \"\"\" Read the data type of a `.gwy` file component. Possible data types are as follows: - 'b': boolean - 'c': character - 'i': 32-bit integer - 'q': 64-bit integer - 'd': double - 's': string - 'o': `.gwy` format object Capitalised versions of some of these data types represent arrays of values of that data type. Arrays are stored as an unsigned 32 bit integer, describing the size of the array, followed by the unseparated array values: - 'C': array of characters - 'I': array of 32-bit integers - 'Q': array of 64-bit integers - 'D': array of doubles - 'S': array of strings - 'O': array of objects. Parameters ---------- open_file : BinaryIO An open file object. Returns ------- str Python string (one character long) of the data type of the component's value. \"\"\" return open_file . read ( 1 ) . decode ( \"ascii\" )","title":"GWY"},{"location":"api/gwy/#gwy-modules","text":"For decoding and loading .gwy AFM file format into Python Numpy arrays.","title":"GWY Modules"},{"location":"api/gwy/#AFMReader.gwy.gwy_get_channels","text":"Extract a list of channels and their corresponding dictionary key ids from the .gwy file dictionary. Parameters: Name Type Description Default gwy_file_structure dict Dictionary of the nested object / component structure of a .gwy file. Where the keys are object names and the values are dictionaries of the object's components. required Returns: Type Description dict Dictionary where the keys are the channel names and the values are the dictionary key ids. Examples:","title":"gwy_get_channels"},{"location":"api/gwy/#AFMReader.gwy.gwy_get_channels--using-a-loaded-dictionary-generated-from-a-gwy-file","text":"LoadScans._gwy_get_channels(gwy_file_structure=loaded_gwy_file_dictionary) Source code in AFMReader/gwy.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 def gwy_get_channels ( gwy_file_structure : dict ) -> dict : \"\"\" Extract a list of channels and their corresponding dictionary key ids from the `.gwy` file dictionary. Parameters ---------- gwy_file_structure : dict Dictionary of the nested object / component structure of a `.gwy` file. Where the keys are object names and the values are dictionaries of the object's components. Returns ------- dict Dictionary where the keys are the channel names and the values are the dictionary key ids. Examples -------- # Using a loaded dictionary generated from a `.gwy` file: LoadScans._gwy_get_channels(gwy_file_structure=loaded_gwy_file_dictionary) \"\"\" title_key_pattern = re . compile ( r \"\\d+(?=/data/title)\" ) channel_ids = {} for key , _ in gwy_file_structure . items (): match = re . search ( title_key_pattern , key ) if match : channel = gwy_file_structure [ key ] channel_ids [ channel ] = match . group () return channel_ids","title":"Using a loaded dictionary generated from a For decoding and loading .gwy AFM file format into Python Numpy arrays. gwy_get_channels(gwy_file_structure) Extract a list of channels and their corresponding dictionary key ids from the .gwy file dictionary. Parameters: Name Type Description Default gwy_file_structure dict Dictionary of the nested object / component structure of a .gwy file. Where the keys are object names and the values are dictionaries of the object's components. required Returns: Type Description dict Dictionary where the keys are the channel names and the values are the dictionary key ids. Examples: Using a loaded dictionary generated from a .gwy file: LoadScans._gwy_get_channels(gwy_file_structure=loaded_gwy_file_dictionary) Source code in AFMReader/gwy.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202def gwy_get_channels(gwy_file_structure: dict) -&gt; dict: &quot;&quot;&quot; Extract a list of channels and their corresponding dictionary key ids from the `.gwy` file dictionary. Parameters ---------- gwy_file_structure : dict Dictionary of the nested object / component structure of a `.gwy` file. Where the keys are object names and the values are dictionaries of the object&#39;s components. Returns ------- dict Dictionary where the keys are the channel names and the values are the dictionary key ids. Examples -------- # Using a loaded dictionary generated from a `.gwy` file: LoadScans._gwy_get_channels(gwy_file_structure=loaded_gwy_file_dictionary) &quot;&quot;&quot; title_key_pattern = re.compile(r&quot;\\d+(?=/data/title)&quot;) channel_ids = {} for key, _ in gwy_file_structure.items(): match = re.search(title_key_pattern, key) if match: channel = gwy_file_structure[key] channel_ids[channel] = match.group() return channel_ids gwy_read_component(open_file, initial_byte_pos, data_dict) Parse and extract data from a .gwy file object, starting at the current open file read position. Parameters: Name Type Description Default open_file BinaryIO An open file object. required initial_byte_pos int Initial position, as byte. required data_dict dict Dictionary of .gwy file image properties. required Returns: Type Description int Size of the component in bytes. Source code in AFMReader/gwy.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170def gwy_read_component(open_file: BinaryIO, initial_byte_pos: int, data_dict: dict) -&gt; int: &quot;&quot;&quot; Parse and extract data from a `.gwy` file object, starting at the current open file read position. Parameters ---------- open_file : BinaryIO An open file object. initial_byte_pos : int Initial position, as byte. data_dict : dict Dictionary of `.gwy` file image properties. Returns ------- int Size of the component in bytes. &quot;&quot;&quot; component_name = read_null_terminated_string(open_file=open_file) data_type = read_gwy_component_dtype(open_file=open_file) if data_type == &quot;o&quot;: logger.debug(f&quot;component name: {component_name} | dtype: {data_type} |&quot;) sub_dict: dict[Any, Any] = {} gwy_read_object(open_file=open_file, data_dict=sub_dict) data_dict[component_name] = sub_dict elif data_type == &quot;c&quot;: value = read_char(open_file=open_file) logger.debug(f&quot;component name: {component_name} | dtype: {data_type} | value: {value}&quot;) data_dict[component_name] = value elif data_type == &quot;i&quot;: value = read_uint32(open_file=open_file) # type: ignore logger.debug(f&quot;component name: {component_name} | dtype: {data_type} | value: {value}&quot;) data_dict[component_name] = value elif data_type == &quot;d&quot;: value = read_double(open_file=open_file) # type: ignore logger.debug(f&quot;component name: {component_name} | dtype: {data_type} | value: {value}&quot;) data_dict[component_name] = value elif data_type == &quot;s&quot;: value = read_null_terminated_string(open_file=open_file) logger.debug(f&quot;component name: {component_name} | dtype: {data_type} | value: {value}&quot;) data_dict[component_name] = value elif data_type == &quot;D&quot;: array_size = read_uint32(open_file=open_file) logger.debug(f&quot;component name: {component_name} | dtype: {data_type}&quot;) logger.debug(f&quot;array size: {array_size}&quot;) data = np.zeros(array_size) for index in range(array_size): data[index] = read_double(open_file=open_file) if &quot;xres&quot; in data_dict and &quot;yres&quot; in data_dict: data = data.reshape((data_dict[&quot;xres&quot;], data_dict[&quot;yres&quot;])) data_dict[&quot;data&quot;] = data return open_file.tell() - initial_byte_pos gwy_read_object(open_file, data_dict) Parse and extract data from a .gwy file object, starting at the current open file read position. Parameters: Name Type Description Default open_file BinaryIO An open file object. required data_dict dict Dictionary of .gwy file image properties. required Source code in AFMReader/gwy.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114def gwy_read_object(open_file: BinaryIO, data_dict: dict) -&gt; None: &quot;&quot;&quot; Parse and extract data from a `.gwy` file object, starting at the current open file read position. Parameters ---------- open_file : BinaryIO An open file object. data_dict : dict Dictionary of `.gwy` file image properties. &quot;&quot;&quot; object_name = read_null_terminated_string(open_file=open_file) data_size = read_uint32(open_file) logger.debug(f&quot;OBJECT | name: {object_name} | data_size: {data_size}&quot;) # Read components read_data_size = 0 while read_data_size &lt; data_size: component_data_size = gwy_read_component( open_file=open_file, initial_byte_pos=open_file.tell(), data_dict=data_dict, ) read_data_size += component_data_size load_gwy(file_path, channel) Extract image and pixel to nm scaling from the .gwy file. Parameters: Name Type Description Default file_path Path or str Path to the .gwy file. required channel str Channel name to extract from the .gwy file. required Returns: Type Description tuple(ndarray, float) A tuple containing the image and its pixel to nanometre scaling value. Raises: Type Description FileNotFoundError If the file is not found. ValueError If the channel is not found in the .gwy file. Examples: Load the image and pixel to nanometre scaling factor, available channels are 'Height', 'ZSensor' and 'Height Sensor'. &gt;&gt;&gt; from AFMReader.gwy import load_gwy &gt;&gt;&gt; image, pixel_to_nm = load_gwy(file_path=&quot;path/to/file.gwy&quot;, channel=&quot;Height&quot;) ``` Source code in AFMReader/gwy.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89def load_gwy(file_path: Path | str, channel: str) -&gt; tuple[np.ndarray[Any, np.dtypes.Float64DType], float]: &quot;&quot;&quot; Extract image and pixel to nm scaling from the .gwy file. Parameters ---------- file_path : Path or str Path to the .gwy file. channel : str Channel name to extract from the .gwy file. Returns ------- tuple(np.ndarray, float) A tuple containing the image and its pixel to nanometre scaling value. Raises ------ FileNotFoundError If the file is not found. ValueError If the channel is not found in the .gwy file. Examples -------- Load the image and pixel to nanometre scaling factor, available channels are &#39;Height&#39;, &#39;ZSensor&#39; and &#39;Height Sensor&#39;. &gt;&gt;&gt; from AFMReader.gwy import load_gwy &gt;&gt;&gt; image, pixel_to_nm = load_gwy(file_path=&quot;path/to/file.gwy&quot;, channel=&quot;Height&quot;) ``` &quot;&quot;&quot; logger.info(f&quot;Loading image from : {file_path}&quot;) file_path = Path(file_path) filename = file_path.stem try: image_data_dict: dict[Any, Any] = {} with Path.open(file_path, &quot;rb&quot;) as open_file: # pylint: disable=unspecified-encoding # Read header header = open_file.read(4) logger.debug(f&quot;Gwy file header: {header.decode}&quot;) gwy_read_object(open_file, data_dict=image_data_dict) # For development - uncomment to have an indentation based nested # dictionary output showing the object - component structure and # available keys: # LoadScans._gwy_print_dict_wrapper(gwy_file_dict=image_data_dict) channel_ids = gwy_get_channels(gwy_file_structure=image_data_dict) if channel not in channel_ids: raise KeyError(f&quot;Channel {channel} not found in {file_path.suffix} channel list: {channel_ids}&quot;) # Get the image data image = image_data_dict[f&quot;/{channel_ids[channel]}/data&quot;][&quot;data&quot;] units = image_data_dict[f&quot;/{channel_ids[channel]}/data&quot;][&quot;si_unit_xy&quot;][&quot;unitstr&quot;] # currently only support equal pixel sizes in x and y px_to_nm = image_data_dict[f&quot;/{channel_ids[channel]}/data&quot;][&quot;xreal&quot;] / image.shape[1] # Convert image heights to nanometresQ if units == &quot;m&quot;: image = image * 1e9 px_to_nm = px_to_nm * 1e9 else: raise ValueError( f&quot;Units &#39;{units}&#39; have not been added for .gwy files. Please add \\ an SI to nanometre conversion factor for these units in _gwy_read_component in \\ io.py.&quot; ) except FileNotFoundError: logger.info(f&quot;[{filename}] File not found : {file_path}&quot;) raise return (image, px_to_nm) read_gwy_component_dtype(open_file) Read the data type of a .gwy file component. Possible data types are as follows: 'b': boolean 'c': character 'i': 32-bit integer 'q': 64-bit integer 'd': double 's': string 'o': .gwy format object Capitalised versions of some of these data types represent arrays of values of that data type. Arrays are stored as an unsigned 32 bit integer, describing the size of the array, followed by the unseparated array values: 'C': array of characters 'I': array of 32-bit integers 'Q': array of 64-bit integers 'D': array of doubles 'S': array of strings 'O': array of objects. Parameters: Name Type Description Default open_file BinaryIO An open file object. required Returns: Type Description str Python string (one character long) of the data type of the component's value. Source code in AFMReader/gwy.py 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239def read_gwy_component_dtype(open_file: BinaryIO) -&gt; str: &quot;&quot;&quot; Read the data type of a `.gwy` file component. Possible data types are as follows: - &#39;b&#39;: boolean - &#39;c&#39;: character - &#39;i&#39;: 32-bit integer - &#39;q&#39;: 64-bit integer - &#39;d&#39;: double - &#39;s&#39;: string - &#39;o&#39;: `.gwy` format object Capitalised versions of some of these data types represent arrays of values of that data type. Arrays are stored as an unsigned 32 bit integer, describing the size of the array, followed by the unseparated array values: - &#39;C&#39;: array of characters - &#39;I&#39;: array of 32-bit integers - &#39;Q&#39;: array of 64-bit integers - &#39;D&#39;: array of doubles - &#39;S&#39;: array of strings - &#39;O&#39;: array of objects. Parameters ---------- open_file : BinaryIO An open file object. Returns ------- str Python string (one character long) of the data type of the component&#39;s value. &quot;&quot;&quot; return open_file.read(1).decode(&quot;ascii&quot;) file:"},{"location":"api/gwy/#AFMReader.gwy.gwy_read_component","text":"Parse and extract data from a .gwy file object, starting at the current open file read position. Parameters: Name Type Description Default open_file BinaryIO An open file object. required initial_byte_pos int Initial position, as byte. required data_dict dict Dictionary of .gwy file image properties. required Returns: Type Description int Size of the component in bytes. Source code in AFMReader/gwy.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def gwy_read_component ( open_file : BinaryIO , initial_byte_pos : int , data_dict : dict ) -> int : \"\"\" Parse and extract data from a `.gwy` file object, starting at the current open file read position. Parameters ---------- open_file : BinaryIO An open file object. initial_byte_pos : int Initial position, as byte. data_dict : dict Dictionary of `.gwy` file image properties. Returns ------- int Size of the component in bytes. \"\"\" component_name = read_null_terminated_string ( open_file = open_file ) data_type = read_gwy_component_dtype ( open_file = open_file ) if data_type == \"o\" : logger . debug ( f \"component name: { component_name } | dtype: { data_type } |\" ) sub_dict : dict [ Any , Any ] = {} gwy_read_object ( open_file = open_file , data_dict = sub_dict ) data_dict [ component_name ] = sub_dict elif data_type == \"c\" : value = read_char ( open_file = open_file ) logger . debug ( f \"component name: { component_name } | dtype: { data_type } | value: { value } \" ) data_dict [ component_name ] = value elif data_type == \"i\" : value = read_uint32 ( open_file = open_file ) # type: ignore logger . debug ( f \"component name: { component_name } | dtype: { data_type } | value: { value } \" ) data_dict [ component_name ] = value elif data_type == \"d\" : value = read_double ( open_file = open_file ) # type: ignore logger . debug ( f \"component name: { component_name } | dtype: { data_type } | value: { value } \" ) data_dict [ component_name ] = value elif data_type == \"s\" : value = read_null_terminated_string ( open_file = open_file ) logger . debug ( f \"component name: { component_name } | dtype: { data_type } | value: { value } \" ) data_dict [ component_name ] = value elif data_type == \"D\" : array_size = read_uint32 ( open_file = open_file ) logger . debug ( f \"component name: { component_name } | dtype: { data_type } \" ) logger . debug ( f \"array size: { array_size } \" ) data = np . zeros ( array_size ) for index in range ( array_size ): data [ index ] = read_double ( open_file = open_file ) if \"xres\" in data_dict and \"yres\" in data_dict : data = data . reshape (( data_dict [ \"xres\" ], data_dict [ \"yres\" ])) data_dict [ \"data\" ] = data return open_file . tell () - initial_byte_pos","title":"gwy_read_component"},{"location":"api/gwy/#AFMReader.gwy.gwy_read_object","text":"Parse and extract data from a .gwy file object, starting at the current open file read position. Parameters: Name Type Description Default open_file BinaryIO An open file object. required data_dict dict Dictionary of .gwy file image properties. required Source code in AFMReader/gwy.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 def gwy_read_object ( open_file : BinaryIO , data_dict : dict ) -> None : \"\"\" Parse and extract data from a `.gwy` file object, starting at the current open file read position. Parameters ---------- open_file : BinaryIO An open file object. data_dict : dict Dictionary of `.gwy` file image properties. \"\"\" object_name = read_null_terminated_string ( open_file = open_file ) data_size = read_uint32 ( open_file ) logger . debug ( f \"OBJECT | name: { object_name } | data_size: { data_size } \" ) # Read components read_data_size = 0 while read_data_size < data_size : component_data_size = gwy_read_component ( open_file = open_file , initial_byte_pos = open_file . tell (), data_dict = data_dict , ) read_data_size += component_data_size","title":"gwy_read_object"},{"location":"api/gwy/#AFMReader.gwy.load_gwy","text":"Extract image and pixel to nm scaling from the .gwy file. Parameters: Name Type Description Default file_path Path or str Path to the .gwy file. required channel str Channel name to extract from the .gwy file. required Returns: Type Description tuple ( ndarray , float ) A tuple containing the image and its pixel to nanometre scaling value. Raises: Type Description FileNotFoundError If the file is not found. ValueError If the channel is not found in the .gwy file. Examples: Load the image and pixel to nanometre scaling factor, available channels are 'Height', 'ZSensor' and 'Height Sensor'. >>> from AFMReader.gwy import load_gwy >>> image , pixel_to_nm = load_gwy ( file_path = \"path/to/file.gwy\" , channel = \"Height\" ) ``` Source code in AFMReader/gwy.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 def load_gwy ( file_path : Path | str , channel : str ) -> tuple [ np . ndarray [ Any , np . dtypes . Float64DType ], float ]: \"\"\" Extract image and pixel to nm scaling from the .gwy file. Parameters ---------- file_path : Path or str Path to the .gwy file. channel : str Channel name to extract from the .gwy file. Returns ------- tuple(np.ndarray, float) A tuple containing the image and its pixel to nanometre scaling value. Raises ------ FileNotFoundError If the file is not found. ValueError If the channel is not found in the .gwy file. Examples -------- Load the image and pixel to nanometre scaling factor, available channels are 'Height', 'ZSensor' and 'Height Sensor'. >>> from AFMReader.gwy import load_gwy >>> image, pixel_to_nm = load_gwy(file_path=\"path/to/file.gwy\", channel=\"Height\") ``` \"\"\" logger . info ( f \"Loading image from : { file_path } \" ) file_path = Path ( file_path ) filename = file_path . stem try : image_data_dict : dict [ Any , Any ] = {} with Path . open ( file_path , \"rb\" ) as open_file : # pylint: disable=unspecified-encoding # Read header header = open_file . read ( 4 ) logger . debug ( f \"Gwy file header: { header . decode } \" ) gwy_read_object ( open_file , data_dict = image_data_dict ) # For development - uncomment to have an indentation based nested # dictionary output showing the object - component structure and # available keys: # LoadScans._gwy_print_dict_wrapper(gwy_file_dict=image_data_dict) channel_ids = gwy_get_channels ( gwy_file_structure = image_data_dict ) if channel not in channel_ids : raise KeyError ( f \"Channel { channel } not found in { file_path . suffix } channel list: { channel_ids } \" ) # Get the image data image = image_data_dict [ f \"/ { channel_ids [ channel ] } /data\" ][ \"data\" ] units = image_data_dict [ f \"/ { channel_ids [ channel ] } /data\" ][ \"si_unit_xy\" ][ \"unitstr\" ] # currently only support equal pixel sizes in x and y px_to_nm = image_data_dict [ f \"/ { channel_ids [ channel ] } /data\" ][ \"xreal\" ] / image . shape [ 1 ] # Convert image heights to nanometresQ if units == \"m\" : image = image * 1e9 px_to_nm = px_to_nm * 1e9 else : raise ValueError ( f \"Units ' { units } ' have not been added for .gwy files. Please add \\ an SI to nanometre conversion factor for these units in _gwy_read_component in \\ io.py.\" ) except FileNotFoundError : logger . info ( f \"[ { filename } ] File not found : { file_path } \" ) raise return ( image , px_to_nm )","title":"load_gwy"},{"location":"api/gwy/#AFMReader.gwy.read_gwy_component_dtype","text":"Read the data type of a .gwy file component. Possible data types are as follows: 'b': boolean 'c': character 'i': 32-bit integer 'q': 64-bit integer 'd': double 's': string 'o': .gwy format object Capitalised versions of some of these data types represent arrays of values of that data type. Arrays are stored as an unsigned 32 bit integer, describing the size of the array, followed by the unseparated array values: 'C': array of characters 'I': array of 32-bit integers 'Q': array of 64-bit integers 'D': array of doubles 'S': array of strings 'O': array of objects. Parameters: Name Type Description Default open_file BinaryIO An open file object. required Returns: Type Description str Python string (one character long) of the data type of the component's value. Source code in AFMReader/gwy.py 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 def read_gwy_component_dtype ( open_file : BinaryIO ) -> str : \"\"\" Read the data type of a `.gwy` file component. Possible data types are as follows: - 'b': boolean - 'c': character - 'i': 32-bit integer - 'q': 64-bit integer - 'd': double - 's': string - 'o': `.gwy` format object Capitalised versions of some of these data types represent arrays of values of that data type. Arrays are stored as an unsigned 32 bit integer, describing the size of the array, followed by the unseparated array values: - 'C': array of characters - 'I': array of 32-bit integers - 'Q': array of 64-bit integers - 'D': array of doubles - 'S': array of strings - 'O': array of objects. Parameters ---------- open_file : BinaryIO An open file object. Returns ------- str Python string (one character long) of the data type of the component's value. \"\"\" return open_file . read ( 1 ) . decode ( \"ascii\" )","title":"read_gwy_component_dtype"},{"location":"api/ibw/","text":"IBW Modules For decoding and loading .ibw AFM file format into Python Numpy arrays. load_ibw ( file_path , channel ) Load image from Asylum Research (Igor) .ibw files. Parameters: Name Type Description Default file_path Path | str Path to the .ibw file. required channel str The channel to extract from the .ibw file. required Returns: Type Description tuple [ ndarray , float ] A tuple containing the image and its pixel to nanometre scaling value. Raises: Type Description FileNotFoundError If the file is not found. ValueError If the channel is not found in the .ibw file. Examples: Load the image and pixel to nanometre scaling factor - 'HeightTracee' is the default channel name (the extra 'e' is not a typo!). >>> from AFMReader.ibw import load_ibw >>> image , pixel_to_nanometre_scaling_factor = load_ibw ( file_path = \"./my_ibw_file.ibw\" , channel = \"HeightTracee\" ) Source code in AFMReader/ibw.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def load_ibw ( file_path : Path | str , channel : str ) -> tuple [ np . ndarray , float ]: \"\"\" Load image from Asylum Research (Igor) .ibw files. Parameters ---------- file_path : Path | str Path to the .ibw file. channel : str The channel to extract from the .ibw file. Returns ------- tuple[np.ndarray, float] A tuple containing the image and its pixel to nanometre scaling value. Raises ------ FileNotFoundError If the file is not found. ValueError If the channel is not found in the .ibw file. Examples -------- Load the image and pixel to nanometre scaling factor - 'HeightTracee' is the default channel name (the extra 'e' is not a typo!). >>> from AFMReader.ibw import load_ibw >>> image, pixel_to_nanometre_scaling_factor = load_ibw(file_path=\"./my_ibw_file.ibw\", channel=\"HeightTracee\") \"\"\" logger . info ( f \"Loading image from : { file_path } \" ) file_path = Path ( file_path ) filename = file_path . stem # Check the file exists and raise an error if not if not file_path . is_file (): logger . error ( f \"[ { filename } ] File not found : { file_path } \" ) raise FileNotFoundError ( errno . ENOENT , os . strerror ( errno . ENOENT ), file_path ) try : scan = binarywave . load ( file_path ) logger . info ( f \"[ { filename } ] : Loaded image from : { file_path } \" ) labels = [] for label_list in scan [ \"wave\" ][ \"labels\" ]: for label in label_list : if label : labels . append ( label . decode ()) channel_idx = labels . index ( channel ) image = scan [ \"wave\" ][ \"wData\" ][:, :, channel_idx ] . T * 1e9 # Looks to be in m image = np . flipud ( image ) logger . info ( f \"[ { filename } ] : Extracted channel { channel } \" ) except FileNotFoundError : logger . error ( f \"[ { filename } ] File not found : { file_path } \" ) raise except ValueError : logger . error ( f \"[ { filename } ] : { channel } not in { file_path . suffix } channel list: { labels } \" ) raise except Exception as e : logger . error ( f \"[ { filename } ] : { e } \" ) raise e return ( image , _ibw_pixel_to_nm_scaling ( scan ))","title":"IBW"},{"location":"api/ibw/#ibw-modules","text":"For decoding and loading .ibw AFM file format into Python Numpy arrays.","title":"IBW Modules"},{"location":"api/ibw/#AFMReader.ibw.load_ibw","text":"Load image from Asylum Research (Igor) .ibw files. Parameters: Name Type Description Default file_path Path | str Path to the .ibw file. required channel str The channel to extract from the .ibw file. required Returns: Type Description tuple [ ndarray , float ] A tuple containing the image and its pixel to nanometre scaling value. Raises: Type Description FileNotFoundError If the file is not found. ValueError If the channel is not found in the .ibw file. Examples: Load the image and pixel to nanometre scaling factor - 'HeightTracee' is the default channel name (the extra 'e' is not a typo!). >>> from AFMReader.ibw import load_ibw >>> image , pixel_to_nanometre_scaling_factor = load_ibw ( file_path = \"./my_ibw_file.ibw\" , channel = \"HeightTracee\" ) Source code in AFMReader/ibw.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 def load_ibw ( file_path : Path | str , channel : str ) -> tuple [ np . ndarray , float ]: \"\"\" Load image from Asylum Research (Igor) .ibw files. Parameters ---------- file_path : Path | str Path to the .ibw file. channel : str The channel to extract from the .ibw file. Returns ------- tuple[np.ndarray, float] A tuple containing the image and its pixel to nanometre scaling value. Raises ------ FileNotFoundError If the file is not found. ValueError If the channel is not found in the .ibw file. Examples -------- Load the image and pixel to nanometre scaling factor - 'HeightTracee' is the default channel name (the extra 'e' is not a typo!). >>> from AFMReader.ibw import load_ibw >>> image, pixel_to_nanometre_scaling_factor = load_ibw(file_path=\"./my_ibw_file.ibw\", channel=\"HeightTracee\") \"\"\" logger . info ( f \"Loading image from : { file_path } \" ) file_path = Path ( file_path ) filename = file_path . stem # Check the file exists and raise an error if not if not file_path . is_file (): logger . error ( f \"[ { filename } ] File not found : { file_path } \" ) raise FileNotFoundError ( errno . ENOENT , os . strerror ( errno . ENOENT ), file_path ) try : scan = binarywave . load ( file_path ) logger . info ( f \"[ { filename } ] : Loaded image from : { file_path } \" ) labels = [] for label_list in scan [ \"wave\" ][ \"labels\" ]: for label in label_list : if label : labels . append ( label . decode ()) channel_idx = labels . index ( channel ) image = scan [ \"wave\" ][ \"wData\" ][:, :, channel_idx ] . T * 1e9 # Looks to be in m image = np . flipud ( image ) logger . info ( f \"[ { filename } ] : Extracted channel { channel } \" ) except FileNotFoundError : logger . error ( f \"[ { filename } ] File not found : { file_path } \" ) raise except ValueError : logger . error ( f \"[ { filename } ] : { channel } not in { file_path . suffix } channel list: { labels } \" ) raise except Exception as e : logger . error ( f \"[ { filename } ] : { e } \" ) raise e return ( image , _ibw_pixel_to_nm_scaling ( scan ))","title":"load_ibw"},{"location":"api/io/","text":"IO Modules For reading and writing data from / to files. read_ascii ( open_file , length_bytes = 1 ) Read an ASCII string of defined length from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required length_bytes int Length of the ASCII string in bytes that should be read. Default: 1 byte (1 character). 1 Returns: Type Description str ASCII text decoded from file. Source code in AFMReader/io.py 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 def read_ascii ( open_file : BinaryIO , length_bytes : int = 1 ) -> str : \"\"\" Read an ASCII string of defined length from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. length_bytes : int Length of the ASCII string in bytes that should be read. Default: 1 byte (1 character). Returns ------- str ASCII text decoded from file. \"\"\" return open_file . read ( length_bytes ) . decode ( \"ascii\" ) read_bool ( open_file ) Read a boolean from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description bool Boolean decoded value. Source code in AFMReader/io.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def read_bool ( open_file : BinaryIO ) -> bool : \"\"\" Read a boolean from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- bool Boolean decoded value. \"\"\" return bool ( int . from_bytes ( open_file . read ( 1 ), byteorder = \"little\" )) read_char ( open_file ) Read a character from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open file object. required Returns: Type Description str A string type cast from the decoded character. Source code in AFMReader/io.py 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 def read_char ( open_file : BinaryIO ) -> str : \"\"\" Read a character from an open binary file. Parameters ---------- open_file : BinaryIO An open file object. Returns ------- str A string type cast from the decoded character. \"\"\" return open_file . read ( 1 ) . decode ( \"ascii\" ) read_double ( open_file ) Read an 8 byte double from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description float Float decoded from the double value. Source code in AFMReader/io.py 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 def read_double ( open_file : BinaryIO ) -> float : \"\"\" Read an 8 byte double from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- float Float decoded from the double value. \"\"\" return struct . unpack ( \"d\" , open_file . read ( 8 ))[ 0 ] read_float ( open_file ) Read a float from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description float Float decoded value. Source code in AFMReader/io.py 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def read_float ( open_file : BinaryIO ) -> float : \"\"\" Read a float from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- float Float decoded value. \"\"\" return struct . unpack ( \"f\" , open_file . read ( 4 ))[ 0 ] read_hex_u32 ( open_file ) Read a hex encoded unsigned 32 bit integer value from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description str String representing a hexadecimal encoded integer value. Source code in AFMReader/io.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def read_hex_u32 ( open_file : BinaryIO ) -> str : \"\"\" Read a hex encoded unsigned 32 bit integer value from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- str String representing a hexadecimal encoded integer value. \"\"\" return hex ( struct . unpack ( \"<I\" , open_file . read ( 4 ))[ 0 ]) read_int16 ( open_file ) Read a signed 16 bit integer from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description int Integer decoded value. Source code in AFMReader/io.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def read_int16 ( open_file : BinaryIO ) -> int : \"\"\" Read a signed 16 bit integer from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- int Integer decoded value. \"\"\" return struct . unpack ( \"h\" , open_file . read ( 2 ))[ 0 ] read_int32 ( open_file ) Read a signed 32 bit integer from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description int Integer decoded value. Source code in AFMReader/io.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 def read_int32 ( open_file : BinaryIO ) -> int : \"\"\" Read a signed 32 bit integer from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- int Integer decoded value. \"\"\" return struct . unpack ( \"i\" , open_file . read ( 4 ))[ 0 ] read_int8 ( open_file ) Read a signed 8 bit integer from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description int Integer decoded value. Source code in AFMReader/io.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def read_int8 ( open_file : BinaryIO ) -> int : \"\"\" Read a signed 8 bit integer from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- int Integer decoded value. \"\"\" return struct . unpack ( \"b\" , open_file . read ( 1 ))[ 0 ] read_null_separated_utf8 ( open_file , length_bytes = 2 ) Read an ASCII string of defined length from an open binary file. Each character is separated by a null byte. This encoding is known as UTF-16LE (Little Endian). Eg: b'\\x74\\x00\\x6f\\x00\\x70\\x00\\x6f' would decode to 'topo' in this format. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required length_bytes int Length of the ASCII string in bytes that should be read. Default: 2 bytes (1 UTF-16LE character). 2 Returns: Type Description str ASCII text decoded from file. Source code in AFMReader/io.py 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def read_null_separated_utf8 ( open_file : BinaryIO , length_bytes : int = 2 ) -> str : r \"\"\" Read an ASCII string of defined length from an open binary file. Each character is separated by a null byte. This encoding is known as UTF-16LE (Little Endian). Eg: b'\\x74\\x00\\x6f\\x00\\x70\\x00\\x6f' would decode to 'topo' in this format. Parameters ---------- open_file : BinaryIO An open binary file object. length_bytes : int Length of the ASCII string in bytes that should be read. Default: 2 bytes (1 UTF-16LE character). Returns ------- str ASCII text decoded from file. \"\"\" return open_file . read ( length_bytes ) . replace ( b \" \\x00 \" , b \"\" ) . decode ( \"ascii\" ) read_null_terminated_string ( open_file , encoding = 'utf-8' ) Read an open file from the current position in the open binary file, until the next null value. Parameters: Name Type Description Default open_file BinaryIO An open file object. required encoding str Encoding to use when decoding the bytes. 'utf-8' Returns: Type Description str String of the ASCII decoded bytes before the next null byte. Examples: >>> with open ( \"test.txt\" , \"rb\" ) as f : ... print ( read_null_terminated_string ( f ), encoding = \"utf-8\" ) Source code in AFMReader/io.py 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 def read_null_terminated_string ( open_file : BinaryIO , encoding : str = \"utf-8\" ) -> str : \"\"\" Read an open file from the current position in the open binary file, until the next null value. Parameters ---------- open_file : BinaryIO An open file object. encoding : str Encoding to use when decoding the bytes. Returns ------- str String of the ASCII decoded bytes before the next null byte. Examples -------- >>> with open(\"test.txt\", \"rb\") as f: ... print(read_null_terminated_string(f), encoding=\"utf-8\") \"\"\" byte = open_file . read ( 1 ) value = b \"\" while byte != b \" \\x00 \" : value += byte byte = open_file . read ( 1 ) # Sometimes encodings cannot decode a byte that is not defined in the encoding. # Try 'latin1' in this case as it is able to handle symbols such as micro (\u00b5). try : return str ( value . decode ( encoding = encoding )) except UnicodeDecodeError as e : if \"codec can't decode byte\" in str ( e ): bad_byte = str ( e ) . split ( \"byte \" )[ 1 ] . split ( \":\" )[ 0 ] logger . debug ( f \"Decoding error while reading null terminated string. Encoding { encoding } encountered\" f \" a byte that could not be decoded: { bad_byte } . Trying 'latin1' encoding.\" ) return str ( value . decode ( encoding = \"latin1\" )) raise e read_uint32 ( open_file ) Read an unsigned 32 bit integer from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description int Integer decoded value. Source code in AFMReader/io.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def read_uint32 ( open_file : BinaryIO ) -> int : \"\"\" Read an unsigned 32 bit integer from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- int Integer decoded value. \"\"\" return struct . unpack ( \"<I\" , open_file . read ( 4 ))[ 0 ] read_uint8 ( open_file ) Read an unsigned 8 bit integer from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description int Integer decoded value. Source code in AFMReader/io.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 def read_uint8 ( open_file : BinaryIO ) -> int : \"\"\" Read an unsigned 8 bit integer from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- int Integer decoded value. \"\"\" return int . from_bytes ( open_file . read ( 1 ), byteorder = \"little\" ) read_yaml ( filename ) Read a YAML file. Parameters: Name Type Description Default filename Union [ str , Path ] YAML file to read. required Returns: Type Description Dict Dictionary of the file. Source code in AFMReader/io.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 def read_yaml ( filename : str | Path ) -> dict : \"\"\" Read a YAML file. Parameters ---------- filename : Union[str, Path] YAML file to read. Returns ------- Dict Dictionary of the file. \"\"\" with Path ( filename ) . open ( encoding = \"utf-8\" ) as f : try : yaml_file = YAML ( typ = \"safe\" ) return yaml_file . load ( f ) except YAMLError as exception : logger . error ( exception ) return {} skip_bytes ( open_file , length_bytes = 1 ) Skip a specified number of bytes when reading an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required length_bytes int Number of bytes to skip. 1 Returns: Type Description bytes The bytes that were skipped. Source code in AFMReader/io.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 def skip_bytes ( open_file : BinaryIO , length_bytes : int = 1 ) -> bytes : \"\"\" Skip a specified number of bytes when reading an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. length_bytes : int Number of bytes to skip. Returns ------- bytes The bytes that were skipped. \"\"\" return open_file . read ( length_bytes ) unpack_hdf5 ( open_hdf5_file , group_path = '/' ) Read a dictionary from an open hdf5 file. Parameters: Name Type Description Default open_hdf5_file File An open hdf5 file object. required group_path str Path to the group in the hdf5 file to start reading the data from. '/' Returns: Type Description dict Dictionary containing the data from the hdf5 file. Examples: Read the data from the root group of the hdf5 file. >>> with h5py . File ( \"path/to/file.h5\" , \"r\" ) as f : >>> data = unpack_hdf5 ( open_hdf5_file = f , group_path = \"/\" ) Read data from a particular dataset in the hdf5 file. >>> with h5py . File ( \"path/to/file.h5\" , \"r\" ) as f : >>> data = unpack_hdf5 ( open_hdf5_file = f , group_path = \"/dataset_name\" ) Source code in AFMReader/io.py 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 def unpack_hdf5 ( open_hdf5_file : h5py . File , group_path : str = \"/\" ) -> dict : \"\"\" Read a dictionary from an open hdf5 file. Parameters ---------- open_hdf5_file : h5py.File An open hdf5 file object. group_path : str Path to the group in the hdf5 file to start reading the data from. Returns ------- dict Dictionary containing the data from the hdf5 file. Examples -------- Read the data from the root group of the hdf5 file. >>> with h5py.File(\"path/to/file.h5\", \"r\") as f: >>> data = unpack_hdf5(open_hdf5_file=f, group_path=\"/\") Read data from a particular dataset in the hdf5 file. >>> with h5py.File(\"path/to/file.h5\", \"r\") as f: >>> data = unpack_hdf5(open_hdf5_file=f, group_path=\"/dataset_name\") \"\"\" data = {} for key , item in open_hdf5_file [ group_path ] . items (): if isinstance ( item , h5py . Group ): # Incur recursion for nested groups data [ key ] = unpack_hdf5 ( open_hdf5_file , f \" { group_path } / { key } \" ) # Decode byte strings to utf-8. The data type \"O\" is a byte string. elif isinstance ( item , h5py . Dataset ) and item . dtype == \"O\" : # Byte string data [ key ] = item [()] . decode ( \"utf-8\" ) else : # Another type of dataset data [ key ] = item [()] return data","title":"IO"},{"location":"api/io/#io-modules","text":"For reading and writing data from / to files.","title":"IO Modules"},{"location":"api/io/#AFMReader.io.read_ascii","text":"Read an ASCII string of defined length from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required length_bytes int Length of the ASCII string in bytes that should be read. Default: 1 byte (1 character). 1 Returns: Type Description str ASCII text decoded from file. Source code in AFMReader/io.py 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 def read_ascii ( open_file : BinaryIO , length_bytes : int = 1 ) -> str : \"\"\" Read an ASCII string of defined length from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. length_bytes : int Length of the ASCII string in bytes that should be read. Default: 1 byte (1 character). Returns ------- str ASCII text decoded from file. \"\"\" return open_file . read ( length_bytes ) . decode ( \"ascii\" )","title":"read_ascii"},{"location":"api/io/#AFMReader.io.read_bool","text":"Read a boolean from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description bool Boolean decoded value. Source code in AFMReader/io.py 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 def read_bool ( open_file : BinaryIO ) -> bool : \"\"\" Read a boolean from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- bool Boolean decoded value. \"\"\" return bool ( int . from_bytes ( open_file . read ( 1 ), byteorder = \"little\" ))","title":"read_bool"},{"location":"api/io/#AFMReader.io.read_char","text":"Read a character from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open file object. required Returns: Type Description str A string type cast from the decoded character. Source code in AFMReader/io.py 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 def read_char ( open_file : BinaryIO ) -> str : \"\"\" Read a character from an open binary file. Parameters ---------- open_file : BinaryIO An open file object. Returns ------- str A string type cast from the decoded character. \"\"\" return open_file . read ( 1 ) . decode ( \"ascii\" )","title":"read_char"},{"location":"api/io/#AFMReader.io.read_double","text":"Read an 8 byte double from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description float Float decoded from the double value. Source code in AFMReader/io.py 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 def read_double ( open_file : BinaryIO ) -> float : \"\"\" Read an 8 byte double from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- float Float decoded from the double value. \"\"\" return struct . unpack ( \"d\" , open_file . read ( 8 ))[ 0 ]","title":"read_double"},{"location":"api/io/#AFMReader.io.read_float","text":"Read a float from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description float Float decoded value. Source code in AFMReader/io.py 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def read_float ( open_file : BinaryIO ) -> float : \"\"\" Read a float from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- float Float decoded value. \"\"\" return struct . unpack ( \"f\" , open_file . read ( 4 ))[ 0 ]","title":"read_float"},{"location":"api/io/#AFMReader.io.read_hex_u32","text":"Read a hex encoded unsigned 32 bit integer value from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description str String representing a hexadecimal encoded integer value. Source code in AFMReader/io.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 def read_hex_u32 ( open_file : BinaryIO ) -> str : \"\"\" Read a hex encoded unsigned 32 bit integer value from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- str String representing a hexadecimal encoded integer value. \"\"\" return hex ( struct . unpack ( \"<I\" , open_file . read ( 4 ))[ 0 ])","title":"read_hex_u32"},{"location":"api/io/#AFMReader.io.read_int16","text":"Read a signed 16 bit integer from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description int Integer decoded value. Source code in AFMReader/io.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def read_int16 ( open_file : BinaryIO ) -> int : \"\"\" Read a signed 16 bit integer from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- int Integer decoded value. \"\"\" return struct . unpack ( \"h\" , open_file . read ( 2 ))[ 0 ]","title":"read_int16"},{"location":"api/io/#AFMReader.io.read_int32","text":"Read a signed 32 bit integer from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description int Integer decoded value. Source code in AFMReader/io.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 def read_int32 ( open_file : BinaryIO ) -> int : \"\"\" Read a signed 32 bit integer from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- int Integer decoded value. \"\"\" return struct . unpack ( \"i\" , open_file . read ( 4 ))[ 0 ]","title":"read_int32"},{"location":"api/io/#AFMReader.io.read_int8","text":"Read a signed 8 bit integer from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description int Integer decoded value. Source code in AFMReader/io.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 def read_int8 ( open_file : BinaryIO ) -> int : \"\"\" Read a signed 8 bit integer from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- int Integer decoded value. \"\"\" return struct . unpack ( \"b\" , open_file . read ( 1 ))[ 0 ]","title":"read_int8"},{"location":"api/io/#AFMReader.io.read_null_separated_utf8","text":"Read an ASCII string of defined length from an open binary file. Each character is separated by a null byte. This encoding is known as UTF-16LE (Little Endian). Eg: b'\\x74\\x00\\x6f\\x00\\x70\\x00\\x6f' would decode to 'topo' in this format. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required length_bytes int Length of the ASCII string in bytes that should be read. Default: 2 bytes (1 UTF-16LE character). 2 Returns: Type Description str ASCII text decoded from file. Source code in AFMReader/io.py 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 def read_null_separated_utf8 ( open_file : BinaryIO , length_bytes : int = 2 ) -> str : r \"\"\" Read an ASCII string of defined length from an open binary file. Each character is separated by a null byte. This encoding is known as UTF-16LE (Little Endian). Eg: b'\\x74\\x00\\x6f\\x00\\x70\\x00\\x6f' would decode to 'topo' in this format. Parameters ---------- open_file : BinaryIO An open binary file object. length_bytes : int Length of the ASCII string in bytes that should be read. Default: 2 bytes (1 UTF-16LE character). Returns ------- str ASCII text decoded from file. \"\"\" return open_file . read ( length_bytes ) . replace ( b \" \\x00 \" , b \"\" ) . decode ( \"ascii\" )","title":"read_null_separated_utf8"},{"location":"api/io/#AFMReader.io.read_null_terminated_string","text":"Read an open file from the current position in the open binary file, until the next null value. Parameters: Name Type Description Default open_file BinaryIO An open file object. required encoding str Encoding to use when decoding the bytes. 'utf-8' Returns: Type Description str String of the ASCII decoded bytes before the next null byte. Examples: >>> with open ( \"test.txt\" , \"rb\" ) as f : ... print ( read_null_terminated_string ( f ), encoding = \"utf-8\" ) Source code in AFMReader/io.py 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 def read_null_terminated_string ( open_file : BinaryIO , encoding : str = \"utf-8\" ) -> str : \"\"\" Read an open file from the current position in the open binary file, until the next null value. Parameters ---------- open_file : BinaryIO An open file object. encoding : str Encoding to use when decoding the bytes. Returns ------- str String of the ASCII decoded bytes before the next null byte. Examples -------- >>> with open(\"test.txt\", \"rb\") as f: ... print(read_null_terminated_string(f), encoding=\"utf-8\") \"\"\" byte = open_file . read ( 1 ) value = b \"\" while byte != b \" \\x00 \" : value += byte byte = open_file . read ( 1 ) # Sometimes encodings cannot decode a byte that is not defined in the encoding. # Try 'latin1' in this case as it is able to handle symbols such as micro (\u00b5). try : return str ( value . decode ( encoding = encoding )) except UnicodeDecodeError as e : if \"codec can't decode byte\" in str ( e ): bad_byte = str ( e ) . split ( \"byte \" )[ 1 ] . split ( \":\" )[ 0 ] logger . debug ( f \"Decoding error while reading null terminated string. Encoding { encoding } encountered\" f \" a byte that could not be decoded: { bad_byte } . Trying 'latin1' encoding.\" ) return str ( value . decode ( encoding = \"latin1\" )) raise e","title":"read_null_terminated_string"},{"location":"api/io/#AFMReader.io.read_uint32","text":"Read an unsigned 32 bit integer from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description int Integer decoded value. Source code in AFMReader/io.py 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 def read_uint32 ( open_file : BinaryIO ) -> int : \"\"\" Read an unsigned 32 bit integer from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- int Integer decoded value. \"\"\" return struct . unpack ( \"<I\" , open_file . read ( 4 ))[ 0 ]","title":"read_uint32"},{"location":"api/io/#AFMReader.io.read_uint8","text":"Read an unsigned 8 bit integer from an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required Returns: Type Description int Integer decoded value. Source code in AFMReader/io.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 def read_uint8 ( open_file : BinaryIO ) -> int : \"\"\" Read an unsigned 8 bit integer from an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. Returns ------- int Integer decoded value. \"\"\" return int . from_bytes ( open_file . read ( 1 ), byteorder = \"little\" )","title":"read_uint8"},{"location":"api/io/#AFMReader.io.read_yaml","text":"Read a YAML file. Parameters: Name Type Description Default filename Union [ str , Path ] YAML file to read. required Returns: Type Description Dict Dictionary of the file. Source code in AFMReader/io.py 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 def read_yaml ( filename : str | Path ) -> dict : \"\"\" Read a YAML file. Parameters ---------- filename : Union[str, Path] YAML file to read. Returns ------- Dict Dictionary of the file. \"\"\" with Path ( filename ) . open ( encoding = \"utf-8\" ) as f : try : yaml_file = YAML ( typ = \"safe\" ) return yaml_file . load ( f ) except YAMLError as exception : logger . error ( exception ) return {}","title":"read_yaml"},{"location":"api/io/#AFMReader.io.skip_bytes","text":"Skip a specified number of bytes when reading an open binary file. Parameters: Name Type Description Default open_file BinaryIO An open binary file object. required length_bytes int Number of bytes to skip. 1 Returns: Type Description bytes The bytes that were skipped. Source code in AFMReader/io.py 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 def skip_bytes ( open_file : BinaryIO , length_bytes : int = 1 ) -> bytes : \"\"\" Skip a specified number of bytes when reading an open binary file. Parameters ---------- open_file : BinaryIO An open binary file object. length_bytes : int Number of bytes to skip. Returns ------- bytes The bytes that were skipped. \"\"\" return open_file . read ( length_bytes )","title":"skip_bytes"},{"location":"api/io/#AFMReader.io.unpack_hdf5","text":"Read a dictionary from an open hdf5 file. Parameters: Name Type Description Default open_hdf5_file File An open hdf5 file object. required group_path str Path to the group in the hdf5 file to start reading the data from. '/' Returns: Type Description dict Dictionary containing the data from the hdf5 file. Examples: Read the data from the root group of the hdf5 file. >>> with h5py . File ( \"path/to/file.h5\" , \"r\" ) as f : >>> data = unpack_hdf5 ( open_hdf5_file = f , group_path = \"/\" ) Read data from a particular dataset in the hdf5 file. >>> with h5py . File ( \"path/to/file.h5\" , \"r\" ) as f : >>> data = unpack_hdf5 ( open_hdf5_file = f , group_path = \"/dataset_name\" ) Source code in AFMReader/io.py 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 def unpack_hdf5 ( open_hdf5_file : h5py . File , group_path : str = \"/\" ) -> dict : \"\"\" Read a dictionary from an open hdf5 file. Parameters ---------- open_hdf5_file : h5py.File An open hdf5 file object. group_path : str Path to the group in the hdf5 file to start reading the data from. Returns ------- dict Dictionary containing the data from the hdf5 file. Examples -------- Read the data from the root group of the hdf5 file. >>> with h5py.File(\"path/to/file.h5\", \"r\") as f: >>> data = unpack_hdf5(open_hdf5_file=f, group_path=\"/\") Read data from a particular dataset in the hdf5 file. >>> with h5py.File(\"path/to/file.h5\", \"r\") as f: >>> data = unpack_hdf5(open_hdf5_file=f, group_path=\"/dataset_name\") \"\"\" data = {} for key , item in open_hdf5_file [ group_path ] . items (): if isinstance ( item , h5py . Group ): # Incur recursion for nested groups data [ key ] = unpack_hdf5 ( open_hdf5_file , f \" { group_path } / { key } \" ) # Decode byte strings to utf-8. The data type \"O\" is a byte string. elif isinstance ( item , h5py . Dataset ) and item . dtype == \"O\" : # Byte string data [ key ] = item [()] . decode ( \"utf-8\" ) else : # Another type of dataset data [ key ] = item [()] return data","title":"unpack_hdf5"},{"location":"api/jpk/","text":"JPK Modules For decoding and loading .jpk AFM file format into Python Numpy arrays. load_jpk ( file_path , channel , config_path = None ) Load image from JPK Instruments .jpk files. Parameters: Name Type Description Default file_path Path | str Path to the .jpk file. required channel str The channel to extract from the .jpk file. required config_path Path | str | None Path to a configuration file. If ''None'' (default) then the packages default configuration is loaded from ''default_config.yaml''. None Returns: Type Description tuple [ NDArray , float ] A tuple containing the image and its pixel to nanometre scaling value. Raises: Type Description FileNotFoundError If the file is not found. KeyError If the channel is not found in the file. Examples: Load height trace channel from the .jpk file. 'height_trace' is the default channel name. >>> from AFMReader.jpk import load_jpk >>> image , pixel_to_nanometre_scaling_factor = load_jpk ( file_path = \"./my_jpk_file.jpk\" , channel = \"height_trace\" ) Source code in AFMReader/jpk.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 def load_jpk ( file_path : Path | str , channel : str , config_path : Path | str | None = None ) -> tuple [ np . ndarray , float ]: \"\"\" Load image from JPK Instruments .jpk files. Parameters ---------- file_path : Path | str Path to the .jpk file. channel : str The channel to extract from the .jpk file. config_path : Path | str | None Path to a configuration file. If ''None'' (default) then the packages default configuration is loaded from ''default_config.yaml''. Returns ------- tuple[npt.NDArray, float] A tuple containing the image and its pixel to nanometre scaling value. Raises ------ FileNotFoundError If the file is not found. KeyError If the channel is not found in the file. Examples -------- Load height trace channel from the .jpk file. 'height_trace' is the default channel name. >>> from AFMReader.jpk import load_jpk >>> image, pixel_to_nanometre_scaling_factor = load_jpk(file_path=\"./my_jpk_file.jpk\", channel=\"height_trace\") \"\"\" logger . info ( f \"Loading image from : { file_path } \" ) file_path = Path ( file_path ) filename = file_path . stem jpk_tags = _load_jpk_tags ( config_path ) try : tif = tifffile . TiffFile ( file_path ) except FileNotFoundError : logger . error ( f \"[ { filename } ] File not found : { file_path } \" ) raise # Obtain channel list for all channels in file channel_list = {} for i , page in enumerate ( tif . pages [ 1 :]): # [0] is thumbnail available_channel = page . tags [ jpk_tags [ \"channel_name\" ]] . value # keys are hexadecimal values if page . tags [ jpk_tags [ \"trace_retrace\" ]] . value == 0 : # whether img is trace or retrace tr_rt = \"trace\" else : tr_rt = \"retrace\" channel_list [ f \" { available_channel } _ { tr_rt } \" ] = i + 1 try : channel_idx = channel_list [ channel ] except KeyError : logger . error ( f \" { channel } not in channel list: { channel_list } \" ) raise # Get image and if applicable, scale it channel_page = tif . pages [ channel_idx ] image = channel_page . asarray () scaling , offset = _get_z_scaling ( tif , channel_idx , jpk_tags ) image = ( image * scaling ) + offset if channel_page . tags [ jpk_tags [ \"channel_name\" ]] . value in ( \"height\" , \"measuredHeight\" , \"amplitude\" ): image = image * 1e9 # Get page for common metadata between scans metadata_page = tif . pages [ 0 ] return ( image , _jpk_pixel_to_nm_scaling ( metadata_page , jpk_tags ))","title":"JPK"},{"location":"api/jpk/#jpk-modules","text":"For decoding and loading .jpk AFM file format into Python Numpy arrays.","title":"JPK Modules"},{"location":"api/jpk/#AFMReader.jpk.load_jpk","text":"Load image from JPK Instruments .jpk files. Parameters: Name Type Description Default file_path Path | str Path to the .jpk file. required channel str The channel to extract from the .jpk file. required config_path Path | str | None Path to a configuration file. If ''None'' (default) then the packages default configuration is loaded from ''default_config.yaml''. None Returns: Type Description tuple [ NDArray , float ] A tuple containing the image and its pixel to nanometre scaling value. Raises: Type Description FileNotFoundError If the file is not found. KeyError If the channel is not found in the file. Examples: Load height trace channel from the .jpk file. 'height_trace' is the default channel name. >>> from AFMReader.jpk import load_jpk >>> image , pixel_to_nanometre_scaling_factor = load_jpk ( file_path = \"./my_jpk_file.jpk\" , channel = \"height_trace\" ) Source code in AFMReader/jpk.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 def load_jpk ( file_path : Path | str , channel : str , config_path : Path | str | None = None ) -> tuple [ np . ndarray , float ]: \"\"\" Load image from JPK Instruments .jpk files. Parameters ---------- file_path : Path | str Path to the .jpk file. channel : str The channel to extract from the .jpk file. config_path : Path | str | None Path to a configuration file. If ''None'' (default) then the packages default configuration is loaded from ''default_config.yaml''. Returns ------- tuple[npt.NDArray, float] A tuple containing the image and its pixel to nanometre scaling value. Raises ------ FileNotFoundError If the file is not found. KeyError If the channel is not found in the file. Examples -------- Load height trace channel from the .jpk file. 'height_trace' is the default channel name. >>> from AFMReader.jpk import load_jpk >>> image, pixel_to_nanometre_scaling_factor = load_jpk(file_path=\"./my_jpk_file.jpk\", channel=\"height_trace\") \"\"\" logger . info ( f \"Loading image from : { file_path } \" ) file_path = Path ( file_path ) filename = file_path . stem jpk_tags = _load_jpk_tags ( config_path ) try : tif = tifffile . TiffFile ( file_path ) except FileNotFoundError : logger . error ( f \"[ { filename } ] File not found : { file_path } \" ) raise # Obtain channel list for all channels in file channel_list = {} for i , page in enumerate ( tif . pages [ 1 :]): # [0] is thumbnail available_channel = page . tags [ jpk_tags [ \"channel_name\" ]] . value # keys are hexadecimal values if page . tags [ jpk_tags [ \"trace_retrace\" ]] . value == 0 : # whether img is trace or retrace tr_rt = \"trace\" else : tr_rt = \"retrace\" channel_list [ f \" { available_channel } _ { tr_rt } \" ] = i + 1 try : channel_idx = channel_list [ channel ] except KeyError : logger . error ( f \" { channel } not in channel list: { channel_list } \" ) raise # Get image and if applicable, scale it channel_page = tif . pages [ channel_idx ] image = channel_page . asarray () scaling , offset = _get_z_scaling ( tif , channel_idx , jpk_tags ) image = ( image * scaling ) + offset if channel_page . tags [ jpk_tags [ \"channel_name\" ]] . value in ( \"height\" , \"measuredHeight\" , \"amplitude\" ): image = image * 1e9 # Get page for common metadata between scans metadata_page = tif . pages [ 0 ] return ( image , _jpk_pixel_to_nm_scaling ( metadata_page , jpk_tags ))","title":"load_jpk"},{"location":"api/logging/","text":"Logging Modules Configure logging.","title":"Logging"},{"location":"api/logging/#logging-modules","text":"Configure logging.","title":"Logging Modules"},{"location":"api/spm/","text":"SPM Modules For decoding and loading .spm AFM file format into Python Numpy arrays. load_spm ( file_path , channel ) Extract image and pixel to nm scaling from the Bruker .spm file. Parameters: Name Type Description Default file_path Path or str Path to the .spm file. required channel str Channel name to extract from the .spm file. required Returns: Type Description tuple ( ndarray , float ) A tuple containing the image and its pixel to nanometre scaling value. Raises: Type Description FileNotFoundError If the file is not found. ValueError If the channel is not found in the .spm file. Examples: Load the image and pixel to nanometre scaling factor, available channels are 'Height', 'ZSensor' and 'Height Sensor'. >>> from AFMReader.spm import load_spm >>> image , pixel_to_nm = load_spm ( file_path = \"path/to/file.spm\" , channel = \"Height\" ) ``` Source code in AFMReader/spm.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def load_spm ( file_path : Path | str , channel : str ) -> tuple : \"\"\" Extract image and pixel to nm scaling from the Bruker .spm file. Parameters ---------- file_path : Path or str Path to the .spm file. channel : str Channel name to extract from the .spm file. Returns ------- tuple(np.ndarray, float) A tuple containing the image and its pixel to nanometre scaling value. Raises ------ FileNotFoundError If the file is not found. ValueError If the channel is not found in the .spm file. Examples -------- Load the image and pixel to nanometre scaling factor, available channels are 'Height', 'ZSensor' and 'Height Sensor'. >>> from AFMReader.spm import load_spm >>> image, pixel_to_nm = load_spm(file_path=\"path/to/file.spm\", channel=\"Height\") ``` \"\"\" logger . info ( f \"Loading image from : { file_path } \" ) file_path = Path ( file_path ) filename = file_path . stem try : scan = pySPM . Bruker ( file_path ) logger . info ( f \"[ { filename } ] : Loaded image from : { file_path } \" ) channel_data = scan . get_channel ( channel ) logger . info ( f \"[ { filename } ] : Extracted channel { channel } \" ) image = np . flipud ( np . array ( channel_data . pixels )) except FileNotFoundError : logger . error ( f \"[ { filename } ] File not found : { file_path } \" ) raise except Exception as e : if \"Channel\" in str ( e ) and \"not found\" in str ( e ): # trying to return the error with options of possible channel values labels = [] for channel_option in [ layer [ b \"@2:Image Data\" ][ 0 ] for layer in scan . layers ]: channel_name = channel_option . decode ( \"latin1\" ) . split ( '\"' )[ 1 ][ 1 : - 1 ] labels . append ( channel_name ) logger . error ( f \"[ { filename } ] : { channel } not in { file_path . suffix } channel list: { labels } \" ) raise ValueError ( f \" { channel } not in { file_path . suffix } channel list: { labels } \" ) from e raise e return ( image , spm_pixel_to_nm_scaling ( filename , channel_data )) spm_pixel_to_nm_scaling ( filename , channel_data ) Extract pixel to nm scaling from the SPM image metadata. Parameters: Name Type Description Default filename str File name. required channel_data SPM_image Channel data from PySPM. required Returns: Type Description float Pixel to nm scaling factor. Source code in AFMReader/spm.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def spm_pixel_to_nm_scaling ( filename : str , channel_data : pySPM . SPM . SPM_image ) -> float : \"\"\" Extract pixel to nm scaling from the SPM image metadata. Parameters ---------- filename : str File name. channel_data : pySPM.SPM.SPM_image Channel data from PySPM. Returns ------- float Pixel to nm scaling factor. \"\"\" unit_dict = { \"pm\" : 1e-3 , \"nm\" : 1 , \"um\" : 1e3 , \"mm\" : 1e6 , } px_to_real = channel_data . pxs () # Has potential for non-square pixels but not yet implimented pixel_to_nm_scaling = ( px_to_real [ 0 ][ 0 ] * unit_dict [ px_to_real [ 0 ][ 1 ]], px_to_real [ 1 ][ 0 ] * unit_dict [ px_to_real [ 1 ][ 1 ]], )[ 0 ] if px_to_real [ 0 ][ 0 ] == 0 and px_to_real [ 1 ][ 0 ] == 0 : pixel_to_nm_scaling = 1 logger . info ( f \"[ { filename } ] : Pixel size not found in metadata, defaulting to 1nm\" ) logger . info ( f \"[ { filename } ] : Pixel to nm scaling : { pixel_to_nm_scaling } \" ) return pixel_to_nm_scaling","title":"SPM"},{"location":"api/spm/#spm-modules","text":"For decoding and loading .spm AFM file format into Python Numpy arrays.","title":"SPM Modules"},{"location":"api/spm/#AFMReader.spm.load_spm","text":"Extract image and pixel to nm scaling from the Bruker .spm file. Parameters: Name Type Description Default file_path Path or str Path to the .spm file. required channel str Channel name to extract from the .spm file. required Returns: Type Description tuple ( ndarray , float ) A tuple containing the image and its pixel to nanometre scaling value. Raises: Type Description FileNotFoundError If the file is not found. ValueError If the channel is not found in the .spm file. Examples: Load the image and pixel to nanometre scaling factor, available channels are 'Height', 'ZSensor' and 'Height Sensor'. >>> from AFMReader.spm import load_spm >>> image , pixel_to_nm = load_spm ( file_path = \"path/to/file.spm\" , channel = \"Height\" ) ``` Source code in AFMReader/spm.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def load_spm ( file_path : Path | str , channel : str ) -> tuple : \"\"\" Extract image and pixel to nm scaling from the Bruker .spm file. Parameters ---------- file_path : Path or str Path to the .spm file. channel : str Channel name to extract from the .spm file. Returns ------- tuple(np.ndarray, float) A tuple containing the image and its pixel to nanometre scaling value. Raises ------ FileNotFoundError If the file is not found. ValueError If the channel is not found in the .spm file. Examples -------- Load the image and pixel to nanometre scaling factor, available channels are 'Height', 'ZSensor' and 'Height Sensor'. >>> from AFMReader.spm import load_spm >>> image, pixel_to_nm = load_spm(file_path=\"path/to/file.spm\", channel=\"Height\") ``` \"\"\" logger . info ( f \"Loading image from : { file_path } \" ) file_path = Path ( file_path ) filename = file_path . stem try : scan = pySPM . Bruker ( file_path ) logger . info ( f \"[ { filename } ] : Loaded image from : { file_path } \" ) channel_data = scan . get_channel ( channel ) logger . info ( f \"[ { filename } ] : Extracted channel { channel } \" ) image = np . flipud ( np . array ( channel_data . pixels )) except FileNotFoundError : logger . error ( f \"[ { filename } ] File not found : { file_path } \" ) raise except Exception as e : if \"Channel\" in str ( e ) and \"not found\" in str ( e ): # trying to return the error with options of possible channel values labels = [] for channel_option in [ layer [ b \"@2:Image Data\" ][ 0 ] for layer in scan . layers ]: channel_name = channel_option . decode ( \"latin1\" ) . split ( '\"' )[ 1 ][ 1 : - 1 ] labels . append ( channel_name ) logger . error ( f \"[ { filename } ] : { channel } not in { file_path . suffix } channel list: { labels } \" ) raise ValueError ( f \" { channel } not in { file_path . suffix } channel list: { labels } \" ) from e raise e return ( image , spm_pixel_to_nm_scaling ( filename , channel_data ))","title":"load_spm"},{"location":"api/spm/#AFMReader.spm.spm_pixel_to_nm_scaling","text":"Extract pixel to nm scaling from the SPM image metadata. Parameters: Name Type Description Default filename str File name. required channel_data SPM_image Channel data from PySPM. required Returns: Type Description float Pixel to nm scaling factor. Source code in AFMReader/spm.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def spm_pixel_to_nm_scaling ( filename : str , channel_data : pySPM . SPM . SPM_image ) -> float : \"\"\" Extract pixel to nm scaling from the SPM image metadata. Parameters ---------- filename : str File name. channel_data : pySPM.SPM.SPM_image Channel data from PySPM. Returns ------- float Pixel to nm scaling factor. \"\"\" unit_dict = { \"pm\" : 1e-3 , \"nm\" : 1 , \"um\" : 1e3 , \"mm\" : 1e6 , } px_to_real = channel_data . pxs () # Has potential for non-square pixels but not yet implimented pixel_to_nm_scaling = ( px_to_real [ 0 ][ 0 ] * unit_dict [ px_to_real [ 0 ][ 1 ]], px_to_real [ 1 ][ 0 ] * unit_dict [ px_to_real [ 1 ][ 1 ]], )[ 0 ] if px_to_real [ 0 ][ 0 ] == 0 and px_to_real [ 1 ][ 0 ] == 0 : pixel_to_nm_scaling = 1 logger . info ( f \"[ { filename } ] : Pixel size not found in metadata, defaulting to 1nm\" ) logger . info ( f \"[ { filename } ] : Pixel to nm scaling : { pixel_to_nm_scaling } \" ) return pixel_to_nm_scaling","title":"spm_pixel_to_nm_scaling"},{"location":"api/topostats/","text":"TopoStats Modules For decoding and loading .topostats (HDF5 format) AFM file format into Python Nympy arrays. load_topostats ( file_path ) Extract image and pixel to nm scaling from the .topostats (HDF5 format) file. Parameters: Name Type Description Default file_path Path or str Path to the .topostats file. required Returns: Type Description dict [ str , Any ] A dictionary containing the image, its pixel to nm scaling factor and nested Numpy arrays representing the analyses performed on the data. Raises: Type Description OSError If the file is not found. Examples: >>> image , pixel_to_nm_scaling = load_topostats ( \"path/to/topostats_file.topostats\" ) Source code in AFMReader/topostats.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def load_topostats ( file_path : Path | str ) -> dict [ str , Any ]: \"\"\" Extract image and pixel to nm scaling from the .topostats (HDF5 format) file. Parameters ---------- file_path : Path or str Path to the .topostats file. Returns ------- dict[str, Any] A dictionary containing the image, its pixel to nm scaling factor and nested Numpy arrays representing the analyses performed on the data. Raises ------ OSError If the file is not found. Examples -------- >>> image, pixel_to_nm_scaling = load_topostats(\"path/to/topostats_file.topostats\") \"\"\" logger . info ( f \"Loading image from : { file_path } \" ) file_path = Path ( file_path ) filename = file_path . stem try : with h5py . File ( file_path , \"r\" ) as f : data = unpack_hdf5 ( open_hdf5_file = f , group_path = \"/\" ) if data [ \"topostats_file_version\" ] >= 0.2 : data [ \"img_path\" ] = Path ( data [ \"img_path\" ]) file_version = data [ \"topostats_file_version\" ] logger . info ( f \"[ { filename } ] TopoStats file version : { file_version } \" ) except OSError as e : if \"Unable to open file\" in str ( e ): logger . error ( f \"[ { filename } ] File not found : { file_path } \" ) raise e return data","title":"TopoStats"},{"location":"api/topostats/#topostats-modules","text":"For decoding and loading .topostats (HDF5 format) AFM file format into Python Nympy arrays.","title":"TopoStats Modules"},{"location":"api/topostats/#AFMReader.topostats.load_topostats","text":"Extract image and pixel to nm scaling from the .topostats (HDF5 format) file. Parameters: Name Type Description Default file_path Path or str Path to the .topostats file. required Returns: Type Description dict [ str , Any ] A dictionary containing the image, its pixel to nm scaling factor and nested Numpy arrays representing the analyses performed on the data. Raises: Type Description OSError If the file is not found. Examples: >>> image , pixel_to_nm_scaling = load_topostats ( \"path/to/topostats_file.topostats\" ) Source code in AFMReader/topostats.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 def load_topostats ( file_path : Path | str ) -> dict [ str , Any ]: \"\"\" Extract image and pixel to nm scaling from the .topostats (HDF5 format) file. Parameters ---------- file_path : Path or str Path to the .topostats file. Returns ------- dict[str, Any] A dictionary containing the image, its pixel to nm scaling factor and nested Numpy arrays representing the analyses performed on the data. Raises ------ OSError If the file is not found. Examples -------- >>> image, pixel_to_nm_scaling = load_topostats(\"path/to/topostats_file.topostats\") \"\"\" logger . info ( f \"Loading image from : { file_path } \" ) file_path = Path ( file_path ) filename = file_path . stem try : with h5py . File ( file_path , \"r\" ) as f : data = unpack_hdf5 ( open_hdf5_file = f , group_path = \"/\" ) if data [ \"topostats_file_version\" ] >= 0.2 : data [ \"img_path\" ] = Path ( data [ \"img_path\" ]) file_version = data [ \"topostats_file_version\" ] logger . info ( f \"[ { filename } ] TopoStats file version : { file_version } \" ) except OSError as e : if \"Unable to open file\" in str ( e ): logger . error ( f \"[ { filename } ] File not found : { file_path } \" ) raise e return data","title":"load_topostats"}]}